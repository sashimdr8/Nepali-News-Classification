{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0974d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import  word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix,recall_score,precision_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model\n",
    "\n",
    "# glove vectorizer dependencies\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fab0775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Size: 520235\n"
     ]
    }
   ],
   "source": [
    "# Read csv dataset and save to df\n",
    "\n",
    "filePath = 'TOTAL_TEXTS_SETOPATI.csv'\n",
    "VALIDATION_SPLIT = 0.3\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "Embedding = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "df = pd.read_csv(filePath)\n",
    "print(\"DataFrame Size: \"+ str(df.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a79251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing {Remove Stop words using nltk}\n",
    "\n",
    "stop_words = stopwords.words(\"nepali\")\n",
    "def string_manipulation(df,column)  : \n",
    "    df[column] = df[column].apply(lambda x: re.sub('[।(),०-९<<?!,—,–,/,’,‘,:,\\u200d]', '', x))\n",
    "    df[column] = df[column].apply(lambda x: \" \".join([i for i in x.split()if i not in (stop_words)]))\n",
    "    return df\n",
    "Data = string_manipulation(df,\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932f2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 663564 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# convert word into vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "embeddings_dict = {}\n",
    "\n",
    "# Used NPVec1: Word Embeddings for Nepali for glove from [https://github.com/nowalab/nepali-word-embeddings]\n",
    "# processed.glove.txt, processed_normalized_stemmed.glove \n",
    "\n",
    "with open(\"processed.glove\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        token = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[token] = vector\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b0ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41fd1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 104047 news texts.\n",
      "Found 104047 news labels.\n"
     ]
    }
   ],
   "source": [
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')\n",
    "\n",
    "newsTexts = Data['text'].tolist()\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = [] # list of label ids\n",
    "allCategoryDataList = Data['catagory']\n",
    "\n",
    "indexCount = 0\n",
    "for category in allCategoryDataList.unique():\n",
    "    labels_index[category] = indexCount\n",
    "    indexCount = indexCount + 1\n",
    "\n",
    "for category in allCategoryDataList.tolist():\n",
    "    labels.append(labels_index[category])\n",
    "        \n",
    "print('Found %s news texts.' % len(newsTexts))\n",
    "print('Found %s news labels.' % len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8058d036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 899236 unique tokens.\n",
      "Shape of data tensor: (104047, 1000)\n",
      "Shape of label tensor: (104047, 63)\n",
      "label tensor: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# finally, vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(newsTexts)\n",
    "sequences = tokenizer.texts_to_sequences(newsTexts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labelsCategorical = to_categorical(np.asarray(labels))\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labelsCategorical.shape)\n",
    "print('label tensor:', labelsCategorical[0])\n",
    "\n",
    "# split the data into a training set(70%) and a validation set(30%)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "finalLabels = labelsCategorical[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = finalLabels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = finalLabels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ed6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "599e9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training model. CNN CNN Model.')\n",
    "\n",
    "# # train a 1D convnet with global maxpooling\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "# embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# x1 = Dropout(0.2)(x)\n",
    "# x2 = MaxPooling1D(5)(x1)\n",
    "# x3 = Conv1D(128, 5, activation='relu')(x2)\n",
    "# x4 = Dropout(0.3)(x3)\n",
    "# x5 = MaxPooling1D(5)(x4)\n",
    "# x6 = Conv1D(128, 5, activation='relu')(x5)\n",
    "# x7 = GlobalMaxPooling1D()(x6)\n",
    "# x8 = Dense(128, activation='relu')(x7)\n",
    "# print(\"len labels:\", str(len(labels_index)))\n",
    "# preds = Dense(len(labels_index), activation='softmax')(x8)\n",
    "\n",
    "# print(\"Preds shape: \", preds.shape)\n",
    "# print(\"sequence_input shape: \", sequence_input.shape)\n",
    "\n",
    "# model = Model(sequence_input, preds)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "# print(\"Shape of x_train: \", x_train.shape)\n",
    "# print(\"Shape of y_train: \", y_train.shape)\n",
    "# print(\"Shape of x_val: \", x_val.shape)\n",
    "# print(\"Shape of y_val: \", y_val.shape)\n",
    "# print(model.output_shape)\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# history = model.fit(x_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=15,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdc8ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('Training model. CNN biLstm Model.')\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding\n",
    "# from tensorflow.keras.layers import Bidirectional\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Activation\n",
    "\n",
    "\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "# embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(embedding_layer)\n",
    "# # model.add(Embedding(embedded_sequences, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "# model.add(Dropout(0.2)) # embedding dropouts\n",
    "# model.add(Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.2, activation = 'tanh'))) # weight drop on recurrent layers using recurrent_dropout\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(63))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.summary()\n",
    "# model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "\n",
    "# # train the model\n",
    "# # model.fit(x_train, y_train, X_val=x_val, y_val=y_val,\n",
    "# #     epoch_num=15, optimizer='adam', verbose=True)\n",
    "# history = model.fit(x_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=15,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "385763db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1000, 300)    6000000     ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 996, 128)     192128      ['embedding_1[13][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_13 (MaxPooling1D  (None, 199, 128)    0           ['conv1d_16[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 199, 128)     0           ['max_pooling1d_13[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_16 (Bidirectiona  (None, 199, 256)    263168      ['dropout_23[0][0]']             \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 199, 256)     65792       ['bidirectional_16[0][0]']       \n",
      "                                                                                                  \n",
      " attention_vec (Permute)        (None, 199, 256)     0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 199, 512)     0           ['bidirectional_16[0][0]',       \n",
      "                                                                  'attention_vec[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)           (None, 101888)       0           ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 63)           6419007     ['flatten_14[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,940,095\n",
      "Trainable params: 6,940,095\n",
      "Non-trainable params: 6,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n",
      "1139/1139 [==============================] - 1175s 1s/step - loss: 0.0097 - acc: 0.5572 - f1_m: 0.5504 - precision_m: 0.7606 - recall_m: 0.4515 - val_loss: 0.0075 - val_acc: 0.6752 - val_f1_m: 0.6492 - val_precision_m: 0.8418 - val_recall_m: 0.5304\n",
      "Epoch 2/250\n",
      "1139/1139 [==============================] - 1204s 1s/step - loss: 0.0068 - acc: 0.7028 - f1_m: 0.7019 - precision_m: 0.8143 - recall_m: 0.6189 - val_loss: 0.0066 - val_acc: 0.7193 - val_f1_m: 0.7218 - val_precision_m: 0.7940 - val_recall_m: 0.6627\n",
      "Epoch 3/250\n",
      "1139/1139 [==============================] - 1178s 1s/step - loss: 0.0062 - acc: 0.7366 - f1_m: 0.7350 - precision_m: 0.8309 - recall_m: 0.6608 - val_loss: 0.0064 - val_acc: 0.7286 - val_f1_m: 0.7323 - val_precision_m: 0.7844 - val_recall_m: 0.6878\n",
      "Epoch 4/250\n",
      "1139/1139 [==============================] - 1183s 1s/step - loss: 0.0056 - acc: 0.7627 - f1_m: 0.7627 - precision_m: 0.8443 - recall_m: 0.6970 - val_loss: 0.0061 - val_acc: 0.7427 - val_f1_m: 0.7358 - val_precision_m: 0.8178 - val_recall_m: 0.6699\n",
      "Epoch 5/250\n",
      "1139/1139 [==============================] - 1196s 1s/step - loss: 0.0051 - acc: 0.7859 - f1_m: 0.7831 - precision_m: 0.8557 - recall_m: 0.7235 - val_loss: 0.0060 - val_acc: 0.7465 - val_f1_m: 0.7466 - val_precision_m: 0.7968 - val_recall_m: 0.7033\n",
      "Epoch 6/250\n",
      "1139/1139 [==============================] - 1160s 1s/step - loss: 0.0047 - acc: 0.8068 - f1_m: 0.8047 - precision_m: 0.8700 - recall_m: 0.7499 - val_loss: 0.0061 - val_acc: 0.7402 - val_f1_m: 0.7349 - val_precision_m: 0.8096 - val_recall_m: 0.6740\n",
      "Epoch 7/250\n",
      "1139/1139 [==============================] - 1186s 1s/step - loss: 0.0043 - acc: 0.8260 - f1_m: 0.8236 - precision_m: 0.8822 - recall_m: 0.7737 - val_loss: 0.0063 - val_acc: 0.7375 - val_f1_m: 0.7364 - val_precision_m: 0.7844 - val_recall_m: 0.6951\n",
      "Epoch 8/250\n",
      "1139/1139 [==============================] - 1188s 1s/step - loss: 0.0040 - acc: 0.8399 - f1_m: 0.8381 - precision_m: 0.8922 - recall_m: 0.7914 - val_loss: 0.0064 - val_acc: 0.7419 - val_f1_m: 0.7447 - val_precision_m: 0.7728 - val_recall_m: 0.7194\n",
      "Epoch 9/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0036 - acc: 0.8545 - f1_m: 0.8529 - precision_m: 0.9022 - recall_m: 0.8099 - val_loss: 0.0062 - val_acc: 0.7506 - val_f1_m: 0.7502 - val_precision_m: 0.7919 - val_recall_m: 0.7136\n",
      "Epoch 10/250\n",
      "1139/1139 [==============================] - 1189s 1s/step - loss: 0.0034 - acc: 0.8665 - f1_m: 0.8638 - precision_m: 0.9083 - recall_m: 0.8244 - val_loss: 0.0062 - val_acc: 0.7498 - val_f1_m: 0.7485 - val_precision_m: 0.7876 - val_recall_m: 0.7142\n",
      "Epoch 11/250\n",
      "1139/1139 [==============================] - 1192s 1s/step - loss: 0.0032 - acc: 0.8751 - f1_m: 0.8718 - precision_m: 0.9133 - recall_m: 0.8350 - val_loss: 0.0064 - val_acc: 0.7459 - val_f1_m: 0.7448 - val_precision_m: 0.7858 - val_recall_m: 0.7089\n",
      "Epoch 12/250\n",
      "1139/1139 [==============================] - 1148s 1s/step - loss: 0.0031 - acc: 0.8821 - f1_m: 0.8791 - precision_m: 0.9182 - recall_m: 0.8442 - val_loss: 0.0064 - val_acc: 0.7466 - val_f1_m: 0.7482 - val_precision_m: 0.7764 - val_recall_m: 0.7229\n",
      "Epoch 13/250\n",
      "1139/1139 [==============================] - 1220s 1s/step - loss: 0.0029 - acc: 0.8911 - f1_m: 0.8864 - precision_m: 0.9224 - recall_m: 0.8542 - val_loss: 0.0065 - val_acc: 0.7418 - val_f1_m: 0.7392 - val_precision_m: 0.7956 - val_recall_m: 0.6914\n",
      "Epoch 14/250\n",
      "1139/1139 [==============================] - 1210s 1s/step - loss: 0.0028 - acc: 0.8950 - f1_m: 0.8900 - precision_m: 0.9246 - recall_m: 0.8589 - val_loss: 0.0066 - val_acc: 0.7443 - val_f1_m: 0.7448 - val_precision_m: 0.7751 - val_recall_m: 0.7177\n",
      "Epoch 15/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0028 - acc: 0.8972 - f1_m: 0.8917 - precision_m: 0.9245 - recall_m: 0.8620 - val_loss: 0.0064 - val_acc: 0.7491 - val_f1_m: 0.7479 - val_precision_m: 0.7927 - val_recall_m: 0.7089\n",
      "Epoch 16/250\n",
      "1139/1139 [==============================] - 1198s 1s/step - loss: 0.0026 - acc: 0.9021 - f1_m: 0.8987 - precision_m: 0.9302 - recall_m: 0.8701 - val_loss: 0.0066 - val_acc: 0.7481 - val_f1_m: 0.7494 - val_precision_m: 0.7657 - val_recall_m: 0.7346\n",
      "Epoch 17/250\n",
      "1139/1139 [==============================] - 1242s 1s/step - loss: 0.0025 - acc: 0.9062 - f1_m: 0.9009 - precision_m: 0.9312 - recall_m: 0.8737 - val_loss: 0.0065 - val_acc: 0.7445 - val_f1_m: 0.7439 - val_precision_m: 0.7978 - val_recall_m: 0.6979\n",
      "Epoch 18/250\n",
      "1139/1139 [==============================] - 1295s 1s/step - loss: 0.0026 - acc: 0.9049 - f1_m: 0.8989 - precision_m: 0.9313 - recall_m: 0.8697 - val_loss: 0.0066 - val_acc: 0.7479 - val_f1_m: 0.7484 - val_precision_m: 0.7781 - val_recall_m: 0.7218\n",
      "Epoch 19/250\n",
      "1139/1139 [==============================] - 1291s 1s/step - loss: 0.0024 - acc: 0.9114 - f1_m: 0.9059 - precision_m: 0.9339 - recall_m: 0.8803 - val_loss: 0.0066 - val_acc: 0.7496 - val_f1_m: 0.7496 - val_precision_m: 0.7741 - val_recall_m: 0.7274\n",
      "Epoch 20/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1321s 1s/step - loss: 0.0024 - acc: 0.9142 - f1_m: 0.9082 - precision_m: 0.9357 - recall_m: 0.8831 - val_loss: 0.0067 - val_acc: 0.7431 - val_f1_m: 0.7408 - val_precision_m: 0.7855 - val_recall_m: 0.7019\n",
      "Epoch 21/250\n",
      "1139/1139 [==============================] - 1286s 1s/step - loss: 0.0023 - acc: 0.9151 - f1_m: 0.9098 - precision_m: 0.9368 - recall_m: 0.8852 - val_loss: 0.0066 - val_acc: 0.7474 - val_f1_m: 0.7486 - val_precision_m: 0.7833 - val_recall_m: 0.7177\n",
      "Epoch 22/250\n",
      "1139/1139 [==============================] - 1251s 1s/step - loss: 0.0023 - acc: 0.9165 - f1_m: 0.9115 - precision_m: 0.9377 - recall_m: 0.8875 - val_loss: 0.0066 - val_acc: 0.7484 - val_f1_m: 0.7465 - val_precision_m: 0.7849 - val_recall_m: 0.7127\n",
      "Epoch 23/250\n",
      "1139/1139 [==============================] - 1183s 1s/step - loss: 0.0023 - acc: 0.9184 - f1_m: 0.9129 - precision_m: 0.9386 - recall_m: 0.8893 - val_loss: 0.0068 - val_acc: 0.7485 - val_f1_m: 0.7491 - val_precision_m: 0.7738 - val_recall_m: 0.7268\n",
      "Epoch 24/250\n",
      "1139/1139 [==============================] - 1149s 1s/step - loss: 0.0022 - acc: 0.9201 - f1_m: 0.9139 - precision_m: 0.9392 - recall_m: 0.8908 - val_loss: 0.0067 - val_acc: 0.7480 - val_f1_m: 0.7482 - val_precision_m: 0.7806 - val_recall_m: 0.7194\n",
      "Epoch 25/250\n",
      "1139/1139 [==============================] - 1160s 1s/step - loss: 0.0022 - acc: 0.9218 - f1_m: 0.9152 - precision_m: 0.9399 - recall_m: 0.8924 - val_loss: 0.0068 - val_acc: 0.7472 - val_f1_m: 0.7477 - val_precision_m: 0.7687 - val_recall_m: 0.7286\n",
      "Epoch 26/250\n",
      "1139/1139 [==============================] - 1172s 1s/step - loss: 0.0022 - acc: 0.9230 - f1_m: 0.9159 - precision_m: 0.9405 - recall_m: 0.8933 - val_loss: 0.0069 - val_acc: 0.7362 - val_f1_m: 0.7352 - val_precision_m: 0.7695 - val_recall_m: 0.7046\n",
      "Epoch 27/250\n",
      "1139/1139 [==============================] - 1183s 1s/step - loss: 0.0022 - acc: 0.9220 - f1_m: 0.9155 - precision_m: 0.9401 - recall_m: 0.8930 - val_loss: 0.0067 - val_acc: 0.7494 - val_f1_m: 0.7491 - val_precision_m: 0.7840 - val_recall_m: 0.7181\n",
      "Epoch 28/250\n",
      "1139/1139 [==============================] - 1152s 1s/step - loss: 0.0021 - acc: 0.9253 - f1_m: 0.9195 - precision_m: 0.9431 - recall_m: 0.8978 - val_loss: 0.0067 - val_acc: 0.7500 - val_f1_m: 0.7487 - val_precision_m: 0.7853 - val_recall_m: 0.7163\n",
      "Epoch 29/250\n",
      "1139/1139 [==============================] - 1191s 1s/step - loss: 0.0021 - acc: 0.9262 - f1_m: 0.9206 - precision_m: 0.9442 - recall_m: 0.8989 - val_loss: 0.0067 - val_acc: 0.7488 - val_f1_m: 0.7495 - val_precision_m: 0.7790 - val_recall_m: 0.7230\n",
      "Epoch 30/250\n",
      "1139/1139 [==============================] - 1146s 1s/step - loss: 0.0021 - acc: 0.9263 - f1_m: 0.9194 - precision_m: 0.9421 - recall_m: 0.8985 - val_loss: 0.0067 - val_acc: 0.7499 - val_f1_m: 0.7488 - val_precision_m: 0.7838 - val_recall_m: 0.7178\n",
      "Epoch 31/250\n",
      "1139/1139 [==============================] - 1166s 1s/step - loss: 0.0020 - acc: 0.9296 - f1_m: 0.9229 - precision_m: 0.9456 - recall_m: 0.9020 - val_loss: 0.0068 - val_acc: 0.7418 - val_f1_m: 0.7394 - val_precision_m: 0.7908 - val_recall_m: 0.6953\n",
      "Epoch 32/250\n",
      "1139/1139 [==============================] - 1182s 1s/step - loss: 0.0020 - acc: 0.9290 - f1_m: 0.9237 - precision_m: 0.9459 - recall_m: 0.9033 - val_loss: 0.0068 - val_acc: 0.7443 - val_f1_m: 0.7434 - val_precision_m: 0.7884 - val_recall_m: 0.7044\n",
      "Epoch 33/250\n",
      "1139/1139 [==============================] - 1179s 1s/step - loss: 0.0020 - acc: 0.9300 - f1_m: 0.9235 - precision_m: 0.9458 - recall_m: 0.9030 - val_loss: 0.0068 - val_acc: 0.7475 - val_f1_m: 0.7463 - val_precision_m: 0.7823 - val_recall_m: 0.7145\n",
      "Epoch 34/250\n",
      "1139/1139 [==============================] - 1162s 1s/step - loss: 0.0020 - acc: 0.9303 - f1_m: 0.9241 - precision_m: 0.9455 - recall_m: 0.9044 - val_loss: 0.0068 - val_acc: 0.7452 - val_f1_m: 0.7461 - val_precision_m: 0.7806 - val_recall_m: 0.7156\n",
      "Epoch 35/250\n",
      "1139/1139 [==============================] - 1170s 1s/step - loss: 0.0020 - acc: 0.9306 - f1_m: 0.9240 - precision_m: 0.9458 - recall_m: 0.9039 - val_loss: 0.0069 - val_acc: 0.7445 - val_f1_m: 0.7445 - val_precision_m: 0.7810 - val_recall_m: 0.7121\n",
      "Epoch 36/250\n",
      "1139/1139 [==============================] - 1207s 1s/step - loss: 0.0019 - acc: 0.9327 - f1_m: 0.9261 - precision_m: 0.9475 - recall_m: 0.9063 - val_loss: 0.0068 - val_acc: 0.7493 - val_f1_m: 0.7488 - val_precision_m: 0.7752 - val_recall_m: 0.7251\n",
      "Epoch 37/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0019 - acc: 0.9329 - f1_m: 0.9268 - precision_m: 0.9475 - recall_m: 0.9077 - val_loss: 0.0068 - val_acc: 0.7464 - val_f1_m: 0.7450 - val_precision_m: 0.7841 - val_recall_m: 0.7106\n",
      "Epoch 38/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0019 - acc: 0.9331 - f1_m: 0.9261 - precision_m: 0.9464 - recall_m: 0.9073 - val_loss: 0.0069 - val_acc: 0.7437 - val_f1_m: 0.7448 - val_precision_m: 0.7811 - val_recall_m: 0.7125\n",
      "Epoch 39/250\n",
      "1139/1139 [==============================] - 1176s 1s/step - loss: 0.0020 - acc: 0.9318 - f1_m: 0.9254 - precision_m: 0.9465 - recall_m: 0.9061 - val_loss: 0.0069 - val_acc: 0.7399 - val_f1_m: 0.7395 - val_precision_m: 0.7969 - val_recall_m: 0.6909\n",
      "Epoch 40/250\n",
      "1139/1139 [==============================] - 1201s 1s/step - loss: 0.0019 - acc: 0.9345 - f1_m: 0.9278 - precision_m: 0.9481 - recall_m: 0.9090 - val_loss: 0.0069 - val_acc: 0.7436 - val_f1_m: 0.7443 - val_precision_m: 0.7785 - val_recall_m: 0.7138\n",
      "Epoch 41/250\n",
      "1139/1139 [==============================] - 1189s 1s/step - loss: 0.0019 - acc: 0.9342 - f1_m: 0.9278 - precision_m: 0.9484 - recall_m: 0.9088 - val_loss: 0.0069 - val_acc: 0.7472 - val_f1_m: 0.7457 - val_precision_m: 0.7867 - val_recall_m: 0.7097\n",
      "Epoch 42/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0019 - acc: 0.9350 - f1_m: 0.9287 - precision_m: 0.9487 - recall_m: 0.9101 - val_loss: 0.0069 - val_acc: 0.7456 - val_f1_m: 0.7475 - val_precision_m: 0.7851 - val_recall_m: 0.7141\n",
      "Epoch 43/250\n",
      "1139/1139 [==============================] - 1210s 1s/step - loss: 0.0019 - acc: 0.9356 - f1_m: 0.9281 - precision_m: 0.9480 - recall_m: 0.9096 - val_loss: 0.0070 - val_acc: 0.7434 - val_f1_m: 0.7444 - val_precision_m: 0.7705 - val_recall_m: 0.7208\n",
      "Epoch 44/250\n",
      "1139/1139 [==============================] - 1196s 1s/step - loss: 0.0019 - acc: 0.9356 - f1_m: 0.9284 - precision_m: 0.9481 - recall_m: 0.9102 - val_loss: 0.0070 - val_acc: 0.7471 - val_f1_m: 0.7464 - val_precision_m: 0.7721 - val_recall_m: 0.7231\n",
      "Epoch 45/250\n",
      "1139/1139 [==============================] - 1179s 1s/step - loss: 0.0018 - acc: 0.9368 - f1_m: 0.9298 - precision_m: 0.9495 - recall_m: 0.9117 - val_loss: 0.0070 - val_acc: 0.7425 - val_f1_m: 0.7419 - val_precision_m: 0.7820 - val_recall_m: 0.7066\n",
      "Epoch 46/250\n",
      "1139/1139 [==============================] - 1169s 1s/step - loss: 0.0018 - acc: 0.9360 - f1_m: 0.9297 - precision_m: 0.9493 - recall_m: 0.9116 - val_loss: 0.0070 - val_acc: 0.7445 - val_f1_m: 0.7433 - val_precision_m: 0.7801 - val_recall_m: 0.7108\n",
      "Epoch 47/250\n",
      "1139/1139 [==============================] - 1165s 1s/step - loss: 0.0018 - acc: 0.9365 - f1_m: 0.9306 - precision_m: 0.9505 - recall_m: 0.9121 - val_loss: 0.0069 - val_acc: 0.7463 - val_f1_m: 0.7467 - val_precision_m: 0.7827 - val_recall_m: 0.7147\n",
      "Epoch 48/250\n",
      "1139/1139 [==============================] - 1189s 1s/step - loss: 0.0018 - acc: 0.9381 - f1_m: 0.9312 - precision_m: 0.9501 - recall_m: 0.9137 - val_loss: 0.0070 - val_acc: 0.7430 - val_f1_m: 0.7428 - val_precision_m: 0.7779 - val_recall_m: 0.7117\n",
      "Epoch 49/250\n",
      "1139/1139 [==============================] - 1157s 1s/step - loss: 0.0018 - acc: 0.9373 - f1_m: 0.9300 - precision_m: 0.9487 - recall_m: 0.9126 - val_loss: 0.0070 - val_acc: 0.7459 - val_f1_m: 0.7465 - val_precision_m: 0.7815 - val_recall_m: 0.7153\n",
      "Epoch 50/250\n",
      "1139/1139 [==============================] - 1203s 1s/step - loss: 0.0018 - acc: 0.9377 - f1_m: 0.9314 - precision_m: 0.9507 - recall_m: 0.9136 - val_loss: 0.0069 - val_acc: 0.7439 - val_f1_m: 0.7445 - val_precision_m: 0.7842 - val_recall_m: 0.7096\n",
      "Epoch 51/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1181s 1s/step - loss: 0.0018 - acc: 0.9374 - f1_m: 0.9310 - precision_m: 0.9499 - recall_m: 0.9135 - val_loss: 0.0069 - val_acc: 0.7479 - val_f1_m: 0.7492 - val_precision_m: 0.7816 - val_recall_m: 0.7203\n",
      "Epoch 52/250\n",
      "1139/1139 [==============================] - 1712s 2s/step - loss: 0.0018 - acc: 0.9367 - f1_m: 0.9311 - precision_m: 0.9501 - recall_m: 0.9135 - val_loss: 0.0070 - val_acc: 0.7476 - val_f1_m: 0.7474 - val_precision_m: 0.7759 - val_recall_m: 0.7217\n",
      "Epoch 53/250\n",
      "1139/1139 [==============================] - 1184s 1s/step - loss: 0.0018 - acc: 0.9384 - f1_m: 0.9323 - precision_m: 0.9513 - recall_m: 0.9147 - val_loss: 0.0070 - val_acc: 0.7447 - val_f1_m: 0.7469 - val_precision_m: 0.7803 - val_recall_m: 0.7170\n",
      "Epoch 54/250\n",
      "1139/1139 [==============================] - 1181s 1s/step - loss: 0.0018 - acc: 0.9392 - f1_m: 0.9318 - precision_m: 0.9500 - recall_m: 0.9149 - val_loss: 0.0071 - val_acc: 0.7441 - val_f1_m: 0.7435 - val_precision_m: 0.7716 - val_recall_m: 0.7182\n",
      "Epoch 55/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0018 - acc: 0.9385 - f1_m: 0.9325 - precision_m: 0.9506 - recall_m: 0.9158 - val_loss: 0.0070 - val_acc: 0.7464 - val_f1_m: 0.7459 - val_precision_m: 0.7815 - val_recall_m: 0.7143\n",
      "Epoch 56/250\n",
      "1139/1139 [==============================] - 1228s 1s/step - loss: 0.0018 - acc: 0.9387 - f1_m: 0.9313 - precision_m: 0.9496 - recall_m: 0.9143 - val_loss: 0.0070 - val_acc: 0.7463 - val_f1_m: 0.7464 - val_precision_m: 0.7780 - val_recall_m: 0.7182\n",
      "Epoch 57/250\n",
      "1139/1139 [==============================] - 1202s 1s/step - loss: 0.0018 - acc: 0.9365 - f1_m: 0.9298 - precision_m: 0.9481 - recall_m: 0.9129 - val_loss: 0.0071 - val_acc: 0.7425 - val_f1_m: 0.7392 - val_precision_m: 0.7758 - val_recall_m: 0.7069\n",
      "Epoch 58/250\n",
      "1139/1139 [==============================] - 1226s 1s/step - loss: 0.0018 - acc: 0.9404 - f1_m: 0.9335 - precision_m: 0.9519 - recall_m: 0.9166 - val_loss: 0.0070 - val_acc: 0.7459 - val_f1_m: 0.7467 - val_precision_m: 0.7809 - val_recall_m: 0.7161\n",
      "Epoch 59/250\n",
      "1139/1139 [==============================] - 1233s 1s/step - loss: 0.0017 - acc: 0.9404 - f1_m: 0.9345 - precision_m: 0.9523 - recall_m: 0.9179 - val_loss: 0.0070 - val_acc: 0.7458 - val_f1_m: 0.7462 - val_precision_m: 0.7807 - val_recall_m: 0.7157\n",
      "Epoch 60/250\n",
      "1139/1139 [==============================] - 1197s 1s/step - loss: 0.0018 - acc: 0.9398 - f1_m: 0.9340 - precision_m: 0.9522 - recall_m: 0.9171 - val_loss: 0.0070 - val_acc: 0.7465 - val_f1_m: 0.7466 - val_precision_m: 0.7727 - val_recall_m: 0.7231\n",
      "Epoch 61/250\n",
      "1139/1139 [==============================] - 1213s 1s/step - loss: 0.0017 - acc: 0.9415 - f1_m: 0.9341 - precision_m: 0.9510 - recall_m: 0.9186 - val_loss: 0.0071 - val_acc: 0.7427 - val_f1_m: 0.7449 - val_precision_m: 0.7790 - val_recall_m: 0.7145\n",
      "Epoch 62/250\n",
      "1139/1139 [==============================] - 1210s 1s/step - loss: 0.0017 - acc: 0.9417 - f1_m: 0.9342 - precision_m: 0.9519 - recall_m: 0.9179 - val_loss: 0.0071 - val_acc: 0.7416 - val_f1_m: 0.7427 - val_precision_m: 0.7817 - val_recall_m: 0.7084\n",
      "Epoch 63/250\n",
      "1139/1139 [==============================] - 1183s 1s/step - loss: 0.0017 - acc: 0.9420 - f1_m: 0.9356 - precision_m: 0.9530 - recall_m: 0.9196 - val_loss: 0.0070 - val_acc: 0.7441 - val_f1_m: 0.7432 - val_precision_m: 0.7813 - val_recall_m: 0.7096\n",
      "Epoch 64/250\n",
      "1139/1139 [==============================] - 1194s 1s/step - loss: 0.0017 - acc: 0.9413 - f1_m: 0.9339 - precision_m: 0.9519 - recall_m: 0.9173 - val_loss: 0.0070 - val_acc: 0.7409 - val_f1_m: 0.7427 - val_precision_m: 0.7819 - val_recall_m: 0.7081\n",
      "Epoch 65/250\n",
      "1139/1139 [==============================] - 1181s 1s/step - loss: 0.0017 - acc: 0.9414 - f1_m: 0.9346 - precision_m: 0.9522 - recall_m: 0.9183 - val_loss: 0.0071 - val_acc: 0.7429 - val_f1_m: 0.7440 - val_precision_m: 0.7828 - val_recall_m: 0.7097\n",
      "Epoch 66/250\n",
      "1139/1139 [==============================] - 1203s 1s/step - loss: 0.0018 - acc: 0.9400 - f1_m: 0.9327 - precision_m: 0.9506 - recall_m: 0.9160 - val_loss: 0.0070 - val_acc: 0.7443 - val_f1_m: 0.7481 - val_precision_m: 0.7749 - val_recall_m: 0.7241\n",
      "Epoch 67/250\n",
      "1139/1139 [==============================] - 1186s 1s/step - loss: 0.0017 - acc: 0.9414 - f1_m: 0.9343 - precision_m: 0.9523 - recall_m: 0.9176 - val_loss: 0.0070 - val_acc: 0.7452 - val_f1_m: 0.7471 - val_precision_m: 0.7807 - val_recall_m: 0.7172\n",
      "Epoch 68/250\n",
      "1139/1139 [==============================] - 1155s 1s/step - loss: 0.0017 - acc: 0.9422 - f1_m: 0.9355 - precision_m: 0.9535 - recall_m: 0.9188 - val_loss: 0.0071 - val_acc: 0.7444 - val_f1_m: 0.7450 - val_precision_m: 0.7713 - val_recall_m: 0.7214\n",
      "Epoch 69/250\n",
      "1139/1139 [==============================] - 1162s 1s/step - loss: 0.0017 - acc: 0.9416 - f1_m: 0.9350 - precision_m: 0.9523 - recall_m: 0.9189 - val_loss: 0.0071 - val_acc: 0.7414 - val_f1_m: 0.7422 - val_precision_m: 0.7735 - val_recall_m: 0.7144\n",
      "Epoch 70/250\n",
      "1139/1139 [==============================] - 1152s 1s/step - loss: 0.0017 - acc: 0.9421 - f1_m: 0.9352 - precision_m: 0.9530 - recall_m: 0.9187 - val_loss: 0.0072 - val_acc: 0.7407 - val_f1_m: 0.7408 - val_precision_m: 0.7746 - val_recall_m: 0.7108\n",
      "Epoch 71/250\n",
      "1139/1139 [==============================] - 1154s 1s/step - loss: 0.0017 - acc: 0.9423 - f1_m: 0.9355 - precision_m: 0.9529 - recall_m: 0.9193 - val_loss: 0.0072 - val_acc: 0.7435 - val_f1_m: 0.7438 - val_precision_m: 0.7753 - val_recall_m: 0.7157\n",
      "Epoch 72/250\n",
      "1139/1139 [==============================] - 1154s 1s/step - loss: 0.0017 - acc: 0.9429 - f1_m: 0.9366 - precision_m: 0.9544 - recall_m: 0.9200 - val_loss: 0.0071 - val_acc: 0.7407 - val_f1_m: 0.7398 - val_precision_m: 0.7874 - val_recall_m: 0.6988\n",
      "Epoch 73/250\n",
      "1139/1139 [==============================] - 1187s 1s/step - loss: 0.0017 - acc: 0.9425 - f1_m: 0.9355 - precision_m: 0.9530 - recall_m: 0.9193 - val_loss: 0.0072 - val_acc: 0.7401 - val_f1_m: 0.7391 - val_precision_m: 0.7731 - val_recall_m: 0.7089\n",
      "Epoch 74/250\n",
      "1139/1139 [==============================] - 1183s 1s/step - loss: 0.0017 - acc: 0.9421 - f1_m: 0.9355 - precision_m: 0.9523 - recall_m: 0.9199 - val_loss: 0.0072 - val_acc: 0.7386 - val_f1_m: 0.7379 - val_precision_m: 0.7715 - val_recall_m: 0.7081\n",
      "Epoch 75/250\n",
      "1139/1139 [==============================] - 1190s 1s/step - loss: 0.0017 - acc: 0.9431 - f1_m: 0.9365 - precision_m: 0.9544 - recall_m: 0.9200 - val_loss: 0.0070 - val_acc: 0.7452 - val_f1_m: 0.7454 - val_precision_m: 0.7836 - val_recall_m: 0.7116\n",
      "Epoch 76/250\n",
      "1139/1139 [==============================] - 1178s 1s/step - loss: 0.0017 - acc: 0.9433 - f1_m: 0.9369 - precision_m: 0.9529 - recall_m: 0.9220 - val_loss: 0.0071 - val_acc: 0.7419 - val_f1_m: 0.7447 - val_precision_m: 0.7719 - val_recall_m: 0.7202\n",
      "Epoch 77/250\n",
      "1139/1139 [==============================] - 1152s 1s/step - loss: 0.0017 - acc: 0.9433 - f1_m: 0.9364 - precision_m: 0.9534 - recall_m: 0.9206 - val_loss: 0.0071 - val_acc: 0.7422 - val_f1_m: 0.7428 - val_precision_m: 0.7828 - val_recall_m: 0.7076\n",
      "Epoch 78/250\n",
      "1139/1139 [==============================] - 1162s 1s/step - loss: 0.0017 - acc: 0.9424 - f1_m: 0.9357 - precision_m: 0.9530 - recall_m: 0.9196 - val_loss: 0.0071 - val_acc: 0.7436 - val_f1_m: 0.7436 - val_precision_m: 0.7825 - val_recall_m: 0.7092\n",
      "Epoch 79/250\n",
      "1139/1139 [==============================] - 1182s 1s/step - loss: 0.0017 - acc: 0.9432 - f1_m: 0.9367 - precision_m: 0.9534 - recall_m: 0.9212 - val_loss: 0.0071 - val_acc: 0.7406 - val_f1_m: 0.7394 - val_precision_m: 0.7849 - val_recall_m: 0.6999\n",
      "Epoch 80/250\n",
      "1139/1139 [==============================] - 1179s 1s/step - loss: 0.0017 - acc: 0.9433 - f1_m: 0.9371 - precision_m: 0.9540 - recall_m: 0.9214 - val_loss: 0.0072 - val_acc: 0.7448 - val_f1_m: 0.7451 - val_precision_m: 0.7740 - val_recall_m: 0.7191\n",
      "Epoch 81/250\n",
      "1139/1139 [==============================] - 1161s 1s/step - loss: 0.0017 - acc: 0.9438 - f1_m: 0.9377 - precision_m: 0.9548 - recall_m: 0.9217 - val_loss: 0.0072 - val_acc: 0.7425 - val_f1_m: 0.7432 - val_precision_m: 0.7741 - val_recall_m: 0.7156\n",
      "Epoch 82/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1164s 1s/step - loss: 0.0016 - acc: 0.9443 - f1_m: 0.9384 - precision_m: 0.9553 - recall_m: 0.9227 - val_loss: 0.0072 - val_acc: 0.7424 - val_f1_m: 0.7433 - val_precision_m: 0.7749 - val_recall_m: 0.7151\n",
      "Epoch 83/250\n",
      "1139/1139 [==============================] - 1213s 1s/step - loss: 0.0017 - acc: 0.9435 - f1_m: 0.9361 - precision_m: 0.9533 - recall_m: 0.9201 - val_loss: 0.0071 - val_acc: 0.7429 - val_f1_m: 0.7441 - val_precision_m: 0.7813 - val_recall_m: 0.7113\n",
      "Epoch 84/250\n",
      "1139/1139 [==============================] - 1195s 1s/step - loss: 0.0017 - acc: 0.9437 - f1_m: 0.9376 - precision_m: 0.9545 - recall_m: 0.9219 - val_loss: 0.0072 - val_acc: 0.7442 - val_f1_m: 0.7431 - val_precision_m: 0.7750 - val_recall_m: 0.7146\n",
      "Epoch 85/250\n",
      "1139/1139 [==============================] - 1163s 1s/step - loss: 0.0017 - acc: 0.9444 - f1_m: 0.9376 - precision_m: 0.9548 - recall_m: 0.9217 - val_loss: 0.0071 - val_acc: 0.7426 - val_f1_m: 0.7447 - val_precision_m: 0.7817 - val_recall_m: 0.7120\n",
      "Epoch 86/250\n",
      "1139/1139 [==============================] - 1169s 1s/step - loss: 0.0017 - acc: 0.9446 - f1_m: 0.9370 - precision_m: 0.9534 - recall_m: 0.9218 - val_loss: 0.0072 - val_acc: 0.7441 - val_f1_m: 0.7440 - val_precision_m: 0.7737 - val_recall_m: 0.7175\n",
      "Epoch 87/250\n",
      "1139/1139 [==============================] - 1176s 1s/step - loss: 0.0017 - acc: 0.9438 - f1_m: 0.9359 - precision_m: 0.9521 - recall_m: 0.9208 - val_loss: 0.0072 - val_acc: 0.7437 - val_f1_m: 0.7445 - val_precision_m: 0.7727 - val_recall_m: 0.7191\n",
      "Epoch 88/250\n",
      "1139/1139 [==============================] - 1175s 1s/step - loss: 0.0017 - acc: 0.9441 - f1_m: 0.9373 - precision_m: 0.9537 - recall_m: 0.9221 - val_loss: 0.0072 - val_acc: 0.7392 - val_f1_m: 0.7393 - val_precision_m: 0.7783 - val_recall_m: 0.7050\n",
      "Epoch 89/250\n",
      "1139/1139 [==============================] - 1198s 1s/step - loss: 0.0017 - acc: 0.9435 - f1_m: 0.9361 - precision_m: 0.9524 - recall_m: 0.9210 - val_loss: 0.0072 - val_acc: 0.7416 - val_f1_m: 0.7438 - val_precision_m: 0.7754 - val_recall_m: 0.7156\n",
      "Epoch 90/250\n",
      "1139/1139 [==============================] - 1194s 1s/step - loss: 0.0016 - acc: 0.9453 - f1_m: 0.9387 - precision_m: 0.9549 - recall_m: 0.9237 - val_loss: 0.0072 - val_acc: 0.7442 - val_f1_m: 0.7447 - val_precision_m: 0.7708 - val_recall_m: 0.7213\n",
      "Epoch 91/250\n",
      "1139/1139 [==============================] - 1207s 1s/step - loss: 0.0017 - acc: 0.9456 - f1_m: 0.9382 - precision_m: 0.9540 - recall_m: 0.9236 - val_loss: 0.0071 - val_acc: 0.7442 - val_f1_m: 0.7451 - val_precision_m: 0.7783 - val_recall_m: 0.7157\n",
      "Epoch 92/250\n",
      "1139/1139 [==============================] - 1188s 1s/step - loss: 0.0017 - acc: 0.9454 - f1_m: 0.9384 - precision_m: 0.9556 - recall_m: 0.9225 - val_loss: 0.0071 - val_acc: 0.7456 - val_f1_m: 0.7433 - val_precision_m: 0.7845 - val_recall_m: 0.7071\n",
      "Epoch 93/250\n",
      "1139/1139 [==============================] - 1164s 1s/step - loss: 0.0017 - acc: 0.9436 - f1_m: 0.9367 - precision_m: 0.9535 - recall_m: 0.9211 - val_loss: 0.0072 - val_acc: 0.7406 - val_f1_m: 0.7421 - val_precision_m: 0.7797 - val_recall_m: 0.7089\n",
      "Epoch 94/250\n",
      "1139/1139 [==============================] - 1173s 1s/step - loss: 0.0016 - acc: 0.9451 - f1_m: 0.9387 - precision_m: 0.9553 - recall_m: 0.9233 - val_loss: 0.0071 - val_acc: 0.7423 - val_f1_m: 0.7442 - val_precision_m: 0.7819 - val_recall_m: 0.7109\n",
      "Epoch 95/250\n",
      "1139/1139 [==============================] - 1182s 1s/step - loss: 0.0016 - acc: 0.9461 - f1_m: 0.9397 - precision_m: 0.9564 - recall_m: 0.9242 - val_loss: 0.0072 - val_acc: 0.7436 - val_f1_m: 0.7448 - val_precision_m: 0.7720 - val_recall_m: 0.7204\n",
      "Epoch 96/250\n",
      "1139/1139 [==============================] - 1183s 1s/step - loss: 0.0016 - acc: 0.9450 - f1_m: 0.9393 - precision_m: 0.9553 - recall_m: 0.9245 - val_loss: 0.0072 - val_acc: 0.7441 - val_f1_m: 0.7449 - val_precision_m: 0.7745 - val_recall_m: 0.7184\n",
      "Epoch 97/250\n",
      "1139/1139 [==============================] - 1190s 1s/step - loss: 0.0016 - acc: 0.9448 - f1_m: 0.9388 - precision_m: 0.9551 - recall_m: 0.9237 - val_loss: 0.0072 - val_acc: 0.7442 - val_f1_m: 0.7443 - val_precision_m: 0.7720 - val_recall_m: 0.7194\n",
      "Epoch 98/250\n",
      "1139/1139 [==============================] - 1211s 1s/step - loss: 0.0017 - acc: 0.9459 - f1_m: 0.9384 - precision_m: 0.9545 - recall_m: 0.9234 - val_loss: 0.0072 - val_acc: 0.7438 - val_f1_m: 0.7447 - val_precision_m: 0.7794 - val_recall_m: 0.7139\n",
      "Epoch 99/250\n",
      "1139/1139 [==============================] - 1218s 1s/step - loss: 0.0016 - acc: 0.9459 - f1_m: 0.9399 - precision_m: 0.9558 - recall_m: 0.9252 - val_loss: 0.0072 - val_acc: 0.7450 - val_f1_m: 0.7468 - val_precision_m: 0.7767 - val_recall_m: 0.7199\n",
      "Epoch 100/250\n",
      "1139/1139 [==============================] - 1182s 1s/step - loss: 0.0016 - acc: 0.9457 - f1_m: 0.9389 - precision_m: 0.9549 - recall_m: 0.9240 - val_loss: 0.0072 - val_acc: 0.7467 - val_f1_m: 0.7463 - val_precision_m: 0.7824 - val_recall_m: 0.7142\n",
      "Epoch 101/250\n",
      "1139/1139 [==============================] - 1177s 1s/step - loss: 0.0016 - acc: 0.9454 - f1_m: 0.9380 - precision_m: 0.9546 - recall_m: 0.9226 - val_loss: 0.0072 - val_acc: 0.7462 - val_f1_m: 0.7469 - val_precision_m: 0.7716 - val_recall_m: 0.7246\n",
      "Epoch 102/250\n",
      "1139/1139 [==============================] - 1181s 1s/step - loss: 0.0017 - acc: 0.9455 - f1_m: 0.9385 - precision_m: 0.9546 - recall_m: 0.9235 - val_loss: 0.0072 - val_acc: 0.7431 - val_f1_m: 0.7431 - val_precision_m: 0.7720 - val_recall_m: 0.7171\n",
      "Epoch 103/250\n",
      "1139/1139 [==============================] - 1193s 1s/step - loss: 0.0016 - acc: 0.9450 - f1_m: 0.9391 - precision_m: 0.9554 - recall_m: 0.9239 - val_loss: 0.0073 - val_acc: 0.7448 - val_f1_m: 0.7451 - val_precision_m: 0.7653 - val_recall_m: 0.7267\n",
      "Epoch 104/250\n",
      "1139/1139 [==============================] - 1204s 1s/step - loss: 0.0017 - acc: 0.9458 - f1_m: 0.9388 - precision_m: 0.9550 - recall_m: 0.9238 - val_loss: 0.0072 - val_acc: 0.7443 - val_f1_m: 0.7442 - val_precision_m: 0.7758 - val_recall_m: 0.7159\n",
      "Epoch 105/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0017 - acc: 0.9453 - f1_m: 0.9383 - precision_m: 0.9542 - recall_m: 0.9235 - val_loss: 0.0072 - val_acc: 0.7441 - val_f1_m: 0.7450 - val_precision_m: 0.7770 - val_recall_m: 0.7166\n",
      "Epoch 106/250\n",
      "1139/1139 [==============================] - 1168s 1s/step - loss: 0.0016 - acc: 0.9460 - f1_m: 0.9397 - precision_m: 0.9561 - recall_m: 0.9245 - val_loss: 0.0072 - val_acc: 0.7441 - val_f1_m: 0.7454 - val_precision_m: 0.7792 - val_recall_m: 0.7153\n",
      "Epoch 107/250\n",
      "1139/1139 [==============================] - 1170s 1s/step - loss: 0.0016 - acc: 0.9470 - f1_m: 0.9402 - precision_m: 0.9556 - recall_m: 0.9259 - val_loss: 0.0073 - val_acc: 0.7423 - val_f1_m: 0.7450 - val_precision_m: 0.7666 - val_recall_m: 0.7254\n",
      "Epoch 108/250\n",
      "1139/1139 [==============================] - 1169s 1s/step - loss: 0.0016 - acc: 0.9461 - f1_m: 0.9394 - precision_m: 0.9554 - recall_m: 0.9246 - val_loss: 0.0072 - val_acc: 0.7429 - val_f1_m: 0.7441 - val_precision_m: 0.7736 - val_recall_m: 0.7176\n",
      "Epoch 109/250\n",
      "1139/1139 [==============================] - 1192s 1s/step - loss: 0.0016 - acc: 0.9457 - f1_m: 0.9387 - precision_m: 0.9551 - recall_m: 0.9234 - val_loss: 0.0074 - val_acc: 0.7420 - val_f1_m: 0.7412 - val_precision_m: 0.7623 - val_recall_m: 0.7221\n",
      "Epoch 110/250\n",
      "1139/1139 [==============================] - 1162s 1s/step - loss: 0.0016 - acc: 0.9470 - f1_m: 0.9400 - precision_m: 0.9553 - recall_m: 0.9257 - val_loss: 0.0072 - val_acc: 0.7414 - val_f1_m: 0.7422 - val_precision_m: 0.7783 - val_recall_m: 0.7103\n",
      "Epoch 111/250\n",
      "1139/1139 [==============================] - 1310s 1s/step - loss: 0.0020 - acc: 0.9332 - f1_m: 0.9258 - precision_m: 0.9461 - recall_m: 0.9074 - val_loss: 0.0072 - val_acc: 0.7433 - val_f1_m: 0.7442 - val_precision_m: 0.7783 - val_recall_m: 0.7138\n",
      "Epoch 112/250\n",
      "1139/1139 [==============================] - 1169s 1s/step - loss: 0.0016 - acc: 0.9457 - f1_m: 0.9394 - precision_m: 0.9554 - recall_m: 0.9245 - val_loss: 0.0072 - val_acc: 0.7445 - val_f1_m: 0.7451 - val_precision_m: 0.7753 - val_recall_m: 0.7181\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1178s 1s/step - loss: 0.0016 - acc: 0.9463 - f1_m: 0.9395 - precision_m: 0.9551 - recall_m: 0.9250 - val_loss: 0.0072 - val_acc: 0.7428 - val_f1_m: 0.7440 - val_precision_m: 0.7795 - val_recall_m: 0.7126\n",
      "Epoch 114/250\n",
      "1139/1139 [==============================] - 1190s 1s/step - loss: 0.0017 - acc: 0.9450 - f1_m: 0.9384 - precision_m: 0.9542 - recall_m: 0.9239 - val_loss: 0.0072 - val_acc: 0.7447 - val_f1_m: 0.7465 - val_precision_m: 0.7758 - val_recall_m: 0.7201\n",
      "Epoch 115/250\n",
      "1139/1139 [==============================] - 1175s 1s/step - loss: 0.0016 - acc: 0.9465 - f1_m: 0.9394 - precision_m: 0.9548 - recall_m: 0.9250 - val_loss: 0.0072 - val_acc: 0.7434 - val_f1_m: 0.7442 - val_precision_m: 0.7738 - val_recall_m: 0.7176\n",
      "Epoch 116/250\n",
      "1139/1139 [==============================] - 1151s 1s/step - loss: 0.0017 - acc: 0.9453 - f1_m: 0.9387 - precision_m: 0.9540 - recall_m: 0.9246 - val_loss: 0.0072 - val_acc: 0.7424 - val_f1_m: 0.7422 - val_precision_m: 0.7805 - val_recall_m: 0.7083\n",
      "Epoch 117/250\n",
      "1139/1139 [==============================] - 1247s 1s/step - loss: 0.0017 - acc: 0.9453 - f1_m: 0.9390 - precision_m: 0.9545 - recall_m: 0.9245 - val_loss: 0.0072 - val_acc: 0.7415 - val_f1_m: 0.7411 - val_precision_m: 0.7781 - val_recall_m: 0.7083\n",
      "Epoch 118/250\n",
      "1139/1139 [==============================] - 1692s 1s/step - loss: 0.0016 - acc: 0.9466 - f1_m: 0.9404 - precision_m: 0.9557 - recall_m: 0.9261 - val_loss: 0.0073 - val_acc: 0.7436 - val_f1_m: 0.7446 - val_precision_m: 0.7687 - val_recall_m: 0.7228\n",
      "Epoch 119/250\n",
      "1139/1139 [==============================] - 1191s 1s/step - loss: 0.0016 - acc: 0.9471 - f1_m: 0.9408 - precision_m: 0.9565 - recall_m: 0.9262 - val_loss: 0.0073 - val_acc: 0.7441 - val_f1_m: 0.7449 - val_precision_m: 0.7693 - val_recall_m: 0.7228\n",
      "Epoch 120/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0016 - acc: 0.9477 - f1_m: 0.9399 - precision_m: 0.9553 - recall_m: 0.9257 - val_loss: 0.0073 - val_acc: 0.7410 - val_f1_m: 0.7424 - val_precision_m: 0.7731 - val_recall_m: 0.7148\n",
      "Epoch 121/250\n",
      "1139/1139 [==============================] - 1174s 1s/step - loss: 0.0016 - acc: 0.9468 - f1_m: 0.9399 - precision_m: 0.9550 - recall_m: 0.9259 - val_loss: 0.0073 - val_acc: 0.7432 - val_f1_m: 0.7428 - val_precision_m: 0.7733 - val_recall_m: 0.7154\n",
      "Epoch 122/250\n",
      "1139/1139 [==============================] - 1210s 1s/step - loss: 0.0016 - acc: 0.9472 - f1_m: 0.9401 - precision_m: 0.9548 - recall_m: 0.9265 - val_loss: 0.0073 - val_acc: 0.7418 - val_f1_m: 0.7419 - val_precision_m: 0.7776 - val_recall_m: 0.7103\n",
      "Epoch 123/250\n",
      "1139/1139 [==============================] - 1169s 1s/step - loss: 0.0016 - acc: 0.9468 - f1_m: 0.9403 - precision_m: 0.9566 - recall_m: 0.9253 - val_loss: 0.0072 - val_acc: 0.7448 - val_f1_m: 0.7461 - val_precision_m: 0.7739 - val_recall_m: 0.7212\n",
      "Epoch 124/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0016 - acc: 0.9467 - f1_m: 0.9406 - precision_m: 0.9559 - recall_m: 0.9263 - val_loss: 0.0072 - val_acc: 0.7459 - val_f1_m: 0.7457 - val_precision_m: 0.7767 - val_recall_m: 0.7180\n",
      "Epoch 125/250\n",
      "1139/1139 [==============================] - 1172s 1s/step - loss: 0.0016 - acc: 0.9468 - f1_m: 0.9412 - precision_m: 0.9562 - recall_m: 0.9273 - val_loss: 0.0073 - val_acc: 0.7438 - val_f1_m: 0.7458 - val_precision_m: 0.7716 - val_recall_m: 0.7226\n",
      "Epoch 126/250\n",
      "1139/1139 [==============================] - 1178s 1s/step - loss: 0.0016 - acc: 0.9466 - f1_m: 0.9400 - precision_m: 0.9554 - recall_m: 0.9259 - val_loss: 0.0074 - val_acc: 0.7442 - val_f1_m: 0.7447 - val_precision_m: 0.7638 - val_recall_m: 0.7274\n",
      "Epoch 127/250\n",
      "1139/1139 [==============================] - 1186s 1s/step - loss: 0.0016 - acc: 0.9480 - f1_m: 0.9408 - precision_m: 0.9560 - recall_m: 0.9266 - val_loss: 0.0073 - val_acc: 0.7427 - val_f1_m: 0.7440 - val_precision_m: 0.7739 - val_recall_m: 0.7172\n",
      "Epoch 128/250\n",
      "1139/1139 [==============================] - 1160s 1s/step - loss: 0.0016 - acc: 0.9478 - f1_m: 0.9399 - precision_m: 0.9547 - recall_m: 0.9263 - val_loss: 0.0074 - val_acc: 0.7403 - val_f1_m: 0.7403 - val_precision_m: 0.7715 - val_recall_m: 0.7123\n",
      "Epoch 129/250\n",
      "1139/1139 [==============================] - 1187s 1s/step - loss: 0.0017 - acc: 0.9454 - f1_m: 0.9379 - precision_m: 0.9540 - recall_m: 0.9229 - val_loss: 0.0072 - val_acc: 0.7437 - val_f1_m: 0.7444 - val_precision_m: 0.7783 - val_recall_m: 0.7142\n",
      "Epoch 130/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0016 - acc: 0.9468 - f1_m: 0.9410 - precision_m: 0.9566 - recall_m: 0.9265 - val_loss: 0.0073 - val_acc: 0.7419 - val_f1_m: 0.7445 - val_precision_m: 0.7701 - val_recall_m: 0.7214\n",
      "Epoch 131/250\n",
      "1139/1139 [==============================] - 1549s 1s/step - loss: 0.0016 - acc: 0.9471 - f1_m: 0.9407 - precision_m: 0.9562 - recall_m: 0.9263 - val_loss: 0.0073 - val_acc: 0.7414 - val_f1_m: 0.7430 - val_precision_m: 0.7691 - val_recall_m: 0.7196\n",
      "Epoch 132/250\n",
      "1139/1139 [==============================] - 1154s 1s/step - loss: 0.0016 - acc: 0.9472 - f1_m: 0.9411 - precision_m: 0.9561 - recall_m: 0.9271 - val_loss: 0.0073 - val_acc: 0.7432 - val_f1_m: 0.7440 - val_precision_m: 0.7708 - val_recall_m: 0.7200\n",
      "Epoch 133/250\n",
      "1139/1139 [==============================] - 1166s 1s/step - loss: 0.0016 - acc: 0.9471 - f1_m: 0.9403 - precision_m: 0.9553 - recall_m: 0.9264 - val_loss: 0.0073 - val_acc: 0.7410 - val_f1_m: 0.7427 - val_precision_m: 0.7687 - val_recall_m: 0.7192\n",
      "Epoch 134/250\n",
      "1139/1139 [==============================] - 1178s 1s/step - loss: 0.0016 - acc: 0.9480 - f1_m: 0.9410 - precision_m: 0.9565 - recall_m: 0.9266 - val_loss: 0.0073 - val_acc: 0.7409 - val_f1_m: 0.7414 - val_precision_m: 0.7704 - val_recall_m: 0.7153\n",
      "Epoch 135/250\n",
      "1139/1139 [==============================] - 1154s 1s/step - loss: 0.0016 - acc: 0.9482 - f1_m: 0.9399 - precision_m: 0.9551 - recall_m: 0.9260 - val_loss: 0.0073 - val_acc: 0.7403 - val_f1_m: 0.7388 - val_precision_m: 0.7789 - val_recall_m: 0.7037\n",
      "Epoch 136/250\n",
      "1139/1139 [==============================] - 1154s 1s/step - loss: 0.0016 - acc: 0.9473 - f1_m: 0.9405 - precision_m: 0.9559 - recall_m: 0.9261 - val_loss: 0.0073 - val_acc: 0.7429 - val_f1_m: 0.7432 - val_precision_m: 0.7717 - val_recall_m: 0.7175\n",
      "Epoch 137/250\n",
      "1139/1139 [==============================] - 1157s 1s/step - loss: 0.0016 - acc: 0.9474 - f1_m: 0.9399 - precision_m: 0.9559 - recall_m: 0.9251 - val_loss: 0.0073 - val_acc: 0.7438 - val_f1_m: 0.7445 - val_precision_m: 0.7729 - val_recall_m: 0.7190\n",
      "Epoch 138/250\n",
      "1139/1139 [==============================] - 1156s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9409 - precision_m: 0.9556 - recall_m: 0.9272 - val_loss: 0.0073 - val_acc: 0.7443 - val_f1_m: 0.7461 - val_precision_m: 0.7724 - val_recall_m: 0.7225\n",
      "Epoch 139/250\n",
      "1139/1139 [==============================] - 1168s 1s/step - loss: 0.0016 - acc: 0.9473 - f1_m: 0.9385 - precision_m: 0.9537 - recall_m: 0.9244 - val_loss: 0.0073 - val_acc: 0.7436 - val_f1_m: 0.7442 - val_precision_m: 0.7688 - val_recall_m: 0.7220\n",
      "Epoch 140/250\n",
      "1139/1139 [==============================] - 1167s 1s/step - loss: 0.0016 - acc: 0.9479 - f1_m: 0.9418 - precision_m: 0.9573 - recall_m: 0.9273 - val_loss: 0.0073 - val_acc: 0.7413 - val_f1_m: 0.7422 - val_precision_m: 0.7756 - val_recall_m: 0.7125\n",
      "Epoch 141/250\n",
      "1139/1139 [==============================] - 1193s 1s/step - loss: 0.0016 - acc: 0.9486 - f1_m: 0.9424 - precision_m: 0.9577 - recall_m: 0.9282 - val_loss: 0.0074 - val_acc: 0.7443 - val_f1_m: 0.7447 - val_precision_m: 0.7666 - val_recall_m: 0.7249\n",
      "Epoch 142/250\n",
      "1139/1139 [==============================] - 1158s 1s/step - loss: 0.0016 - acc: 0.9485 - f1_m: 0.9423 - precision_m: 0.9585 - recall_m: 0.9272 - val_loss: 0.0074 - val_acc: 0.7405 - val_f1_m: 0.7418 - val_precision_m: 0.7696 - val_recall_m: 0.7167\n",
      "Epoch 143/250\n",
      "1139/1139 [==============================] - 1150s 1s/step - loss: 0.0016 - acc: 0.9478 - f1_m: 0.9418 - precision_m: 0.9565 - recall_m: 0.9281 - val_loss: 0.0073 - val_acc: 0.7408 - val_f1_m: 0.7425 - val_precision_m: 0.7741 - val_recall_m: 0.7142\n",
      "Epoch 144/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1167s 1s/step - loss: 0.0016 - acc: 0.9479 - f1_m: 0.9418 - precision_m: 0.9576 - recall_m: 0.9271 - val_loss: 0.0073 - val_acc: 0.7442 - val_f1_m: 0.7467 - val_precision_m: 0.7741 - val_recall_m: 0.7222\n",
      "Epoch 145/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0016 - acc: 0.9469 - f1_m: 0.9408 - precision_m: 0.9557 - recall_m: 0.9269 - val_loss: 0.0073 - val_acc: 0.7425 - val_f1_m: 0.7457 - val_precision_m: 0.7764 - val_recall_m: 0.7182\n",
      "Epoch 146/250\n",
      "1139/1139 [==============================] - 1191s 1s/step - loss: 0.0016 - acc: 0.9478 - f1_m: 0.9407 - precision_m: 0.9557 - recall_m: 0.9268 - val_loss: 0.0073 - val_acc: 0.7428 - val_f1_m: 0.7459 - val_precision_m: 0.7705 - val_recall_m: 0.7237\n",
      "Epoch 147/250\n",
      "1139/1139 [==============================] - 1202s 1s/step - loss: 0.0016 - acc: 0.9476 - f1_m: 0.9411 - precision_m: 0.9564 - recall_m: 0.9269 - val_loss: 0.0074 - val_acc: 0.7425 - val_f1_m: 0.7435 - val_precision_m: 0.7689 - val_recall_m: 0.7206\n",
      "Epoch 148/250\n",
      "1139/1139 [==============================] - 1205s 1s/step - loss: 0.0016 - acc: 0.9488 - f1_m: 0.9420 - precision_m: 0.9570 - recall_m: 0.9279 - val_loss: 0.0073 - val_acc: 0.7418 - val_f1_m: 0.7416 - val_precision_m: 0.7814 - val_recall_m: 0.7065\n",
      "Epoch 149/250\n",
      "1139/1139 [==============================] - 1197s 1s/step - loss: 0.0016 - acc: 0.9482 - f1_m: 0.9410 - precision_m: 0.9565 - recall_m: 0.9266 - val_loss: 0.0073 - val_acc: 0.7397 - val_f1_m: 0.7420 - val_precision_m: 0.7805 - val_recall_m: 0.7079\n",
      "Epoch 150/250\n",
      "1139/1139 [==============================] - 1209s 1s/step - loss: 0.0016 - acc: 0.9479 - f1_m: 0.9411 - precision_m: 0.9564 - recall_m: 0.9269 - val_loss: 0.0074 - val_acc: 0.7402 - val_f1_m: 0.7422 - val_precision_m: 0.7721 - val_recall_m: 0.7155\n",
      "Epoch 151/250\n",
      "1139/1139 [==============================] - 1204s 1s/step - loss: 0.0016 - acc: 0.9473 - f1_m: 0.9410 - precision_m: 0.9565 - recall_m: 0.9266 - val_loss: 0.0074 - val_acc: 0.7426 - val_f1_m: 0.7440 - val_precision_m: 0.7690 - val_recall_m: 0.7214\n",
      "Epoch 152/250\n",
      "1139/1139 [==============================] - 1201s 1s/step - loss: 0.0016 - acc: 0.9493 - f1_m: 0.9422 - precision_m: 0.9566 - recall_m: 0.9287 - val_loss: 0.0073 - val_acc: 0.7448 - val_f1_m: 0.7462 - val_precision_m: 0.7684 - val_recall_m: 0.7262\n",
      "Epoch 153/250\n",
      "1139/1139 [==============================] - 1218s 1s/step - loss: 0.0016 - acc: 0.9476 - f1_m: 0.9406 - precision_m: 0.9558 - recall_m: 0.9265 - val_loss: 0.0074 - val_acc: 0.7427 - val_f1_m: 0.7430 - val_precision_m: 0.7645 - val_recall_m: 0.7234\n",
      "Epoch 154/250\n",
      "1139/1139 [==============================] - 1197s 1s/step - loss: 0.0016 - acc: 0.9482 - f1_m: 0.9418 - precision_m: 0.9564 - recall_m: 0.9283 - val_loss: 0.0073 - val_acc: 0.7443 - val_f1_m: 0.7444 - val_precision_m: 0.7759 - val_recall_m: 0.7161\n",
      "Epoch 155/250\n",
      "1139/1139 [==============================] - 1197s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9411 - precision_m: 0.9564 - recall_m: 0.9269 - val_loss: 0.0073 - val_acc: 0.7420 - val_f1_m: 0.7430 - val_precision_m: 0.7760 - val_recall_m: 0.7136\n",
      "Epoch 156/250\n",
      "1139/1139 [==============================] - 1224s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9413 - precision_m: 0.9571 - recall_m: 0.9267 - val_loss: 0.0074 - val_acc: 0.7407 - val_f1_m: 0.7406 - val_precision_m: 0.7681 - val_recall_m: 0.7159\n",
      "Epoch 157/250\n",
      "1139/1139 [==============================] - 1198s 1s/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9411 - precision_m: 0.9562 - recall_m: 0.9271 - val_loss: 0.0073 - val_acc: 0.7425 - val_f1_m: 0.7460 - val_precision_m: 0.7714 - val_recall_m: 0.7230\n",
      "Epoch 158/250\n",
      "1139/1139 [==============================] - 1219s 1s/step - loss: 0.0016 - acc: 0.9480 - f1_m: 0.9417 - precision_m: 0.9561 - recall_m: 0.9283 - val_loss: 0.0074 - val_acc: 0.7425 - val_f1_m: 0.7434 - val_precision_m: 0.7643 - val_recall_m: 0.7244\n",
      "Epoch 159/250\n",
      "1139/1139 [==============================] - 1186s 1s/step - loss: 0.0016 - acc: 0.9485 - f1_m: 0.9414 - precision_m: 0.9558 - recall_m: 0.9280 - val_loss: 0.0074 - val_acc: 0.7404 - val_f1_m: 0.7425 - val_precision_m: 0.7707 - val_recall_m: 0.7172\n",
      "Epoch 160/250\n",
      "1139/1139 [==============================] - 1172s 1s/step - loss: 0.0016 - acc: 0.9477 - f1_m: 0.9413 - precision_m: 0.9553 - recall_m: 0.9284 - val_loss: 0.0075 - val_acc: 0.7406 - val_f1_m: 0.7401 - val_precision_m: 0.7596 - val_recall_m: 0.7225\n",
      "Epoch 161/250\n",
      "1139/1139 [==============================] - 1185s 1s/step - loss: 0.0016 - acc: 0.9486 - f1_m: 0.9418 - precision_m: 0.9569 - recall_m: 0.9278 - val_loss: 0.0074 - val_acc: 0.7432 - val_f1_m: 0.7448 - val_precision_m: 0.7719 - val_recall_m: 0.7202\n",
      "Epoch 162/250\n",
      "1139/1139 [==============================] - 1177s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9417 - precision_m: 0.9568 - recall_m: 0.9276 - val_loss: 0.0074 - val_acc: 0.7376 - val_f1_m: 0.7391 - val_precision_m: 0.7707 - val_recall_m: 0.7108\n",
      "Epoch 163/250\n",
      "1139/1139 [==============================] - 1188s 1s/step - loss: 0.0016 - acc: 0.9477 - f1_m: 0.9406 - precision_m: 0.9557 - recall_m: 0.9266 - val_loss: 0.0074 - val_acc: 0.7404 - val_f1_m: 0.7427 - val_precision_m: 0.7682 - val_recall_m: 0.7197\n",
      "Epoch 164/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0016 - acc: 0.9492 - f1_m: 0.9419 - precision_m: 0.9567 - recall_m: 0.9281 - val_loss: 0.0073 - val_acc: 0.7446 - val_f1_m: 0.7458 - val_precision_m: 0.7725 - val_recall_m: 0.7217\n",
      "Epoch 165/250\n",
      "1139/1139 [==============================] - 1175s 1s/step - loss: 0.0016 - acc: 0.9498 - f1_m: 0.9430 - precision_m: 0.9571 - recall_m: 0.9298 - val_loss: 0.0074 - val_acc: 0.7420 - val_f1_m: 0.7439 - val_precision_m: 0.7717 - val_recall_m: 0.7189\n",
      "Epoch 166/250\n",
      "1139/1139 [==============================] - 1186s 1s/step - loss: 0.0016 - acc: 0.9489 - f1_m: 0.9422 - precision_m: 0.9575 - recall_m: 0.9279 - val_loss: 0.0074 - val_acc: 0.7411 - val_f1_m: 0.7405 - val_precision_m: 0.7682 - val_recall_m: 0.7155\n",
      "Epoch 167/250\n",
      "1139/1139 [==============================] - 1172s 1s/step - loss: 0.0016 - acc: 0.9477 - f1_m: 0.9416 - precision_m: 0.9571 - recall_m: 0.9270 - val_loss: 0.0075 - val_acc: 0.7405 - val_f1_m: 0.7407 - val_precision_m: 0.7622 - val_recall_m: 0.7213\n",
      "Epoch 168/250\n",
      "1139/1139 [==============================] - 1191s 1s/step - loss: 0.0016 - acc: 0.9485 - f1_m: 0.9415 - precision_m: 0.9564 - recall_m: 0.9276 - val_loss: 0.0073 - val_acc: 0.7416 - val_f1_m: 0.7437 - val_precision_m: 0.7762 - val_recall_m: 0.7147\n",
      "Epoch 169/250\n",
      "1139/1139 [==============================] - 1202s 1s/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9425 - precision_m: 0.9581 - recall_m: 0.9279 - val_loss: 0.0074 - val_acc: 0.7395 - val_f1_m: 0.7420 - val_precision_m: 0.7704 - val_recall_m: 0.7167\n",
      "Epoch 170/250\n",
      "1139/1139 [==============================] - 1190s 1s/step - loss: 0.0016 - acc: 0.9497 - f1_m: 0.9425 - precision_m: 0.9581 - recall_m: 0.9281 - val_loss: 0.0074 - val_acc: 0.7426 - val_f1_m: 0.7442 - val_precision_m: 0.7725 - val_recall_m: 0.7188\n",
      "Epoch 171/250\n",
      "1139/1139 [==============================] - 1178s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9417 - precision_m: 0.9563 - recall_m: 0.9281 - val_loss: 0.0074 - val_acc: 0.7417 - val_f1_m: 0.7415 - val_precision_m: 0.7721 - val_recall_m: 0.7141\n",
      "Epoch 172/250\n",
      "1139/1139 [==============================] - 1182s 1s/step - loss: 0.0016 - acc: 0.9493 - f1_m: 0.9435 - precision_m: 0.9587 - recall_m: 0.9295 - val_loss: 0.0073 - val_acc: 0.7424 - val_f1_m: 0.7433 - val_precision_m: 0.7763 - val_recall_m: 0.7138\n",
      "Epoch 173/250\n",
      "1139/1139 [==============================] - 1191s 1s/step - loss: 0.0016 - acc: 0.9483 - f1_m: 0.9419 - precision_m: 0.9571 - recall_m: 0.9277 - val_loss: 0.0075 - val_acc: 0.7383 - val_f1_m: 0.7379 - val_precision_m: 0.7700 - val_recall_m: 0.7093\n",
      "Epoch 174/250\n",
      "1139/1139 [==============================] - 1216s 1s/step - loss: 0.0016 - acc: 0.9489 - f1_m: 0.9419 - precision_m: 0.9572 - recall_m: 0.9276 - val_loss: 0.0074 - val_acc: 0.7397 - val_f1_m: 0.7433 - val_precision_m: 0.7742 - val_recall_m: 0.7157\n",
      "Epoch 175/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1194s 1s/step - loss: 0.0016 - acc: 0.9497 - f1_m: 0.9433 - precision_m: 0.9585 - recall_m: 0.9292 - val_loss: 0.0073 - val_acc: 0.7412 - val_f1_m: 0.7446 - val_precision_m: 0.7758 - val_recall_m: 0.7167\n",
      "Epoch 176/250\n",
      "1139/1139 [==============================] - 1206s 1s/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9412 - precision_m: 0.9563 - recall_m: 0.9273 - val_loss: 0.0075 - val_acc: 0.7403 - val_f1_m: 0.7408 - val_precision_m: 0.7636 - val_recall_m: 0.7202\n",
      "Epoch 177/250\n",
      "1139/1139 [==============================] - 1205s 1s/step - loss: 0.0016 - acc: 0.9472 - f1_m: 0.9401 - precision_m: 0.9561 - recall_m: 0.9252 - val_loss: 0.0074 - val_acc: 0.7414 - val_f1_m: 0.7429 - val_precision_m: 0.7668 - val_recall_m: 0.7213\n",
      "Epoch 178/250\n",
      "1139/1139 [==============================] - 1193s 1s/step - loss: 0.0016 - acc: 0.9486 - f1_m: 0.9421 - precision_m: 0.9571 - recall_m: 0.9281 - val_loss: 0.0074 - val_acc: 0.7411 - val_f1_m: 0.7432 - val_precision_m: 0.7686 - val_recall_m: 0.7203\n",
      "Epoch 179/250\n",
      "1139/1139 [==============================] - 1206s 1s/step - loss: 0.0016 - acc: 0.9492 - f1_m: 0.9428 - precision_m: 0.9578 - recall_m: 0.9288 - val_loss: 0.0075 - val_acc: 0.7401 - val_f1_m: 0.7415 - val_precision_m: 0.7643 - val_recall_m: 0.7208\n",
      "Epoch 180/250\n",
      "1139/1139 [==============================] - 1199s 1s/step - loss: 0.0016 - acc: 0.9491 - f1_m: 0.9424 - precision_m: 0.9573 - recall_m: 0.9286 - val_loss: 0.0074 - val_acc: 0.7436 - val_f1_m: 0.7449 - val_precision_m: 0.7667 - val_recall_m: 0.7252\n",
      "Epoch 181/250\n",
      "1139/1139 [==============================] - 1200s 1s/step - loss: 0.0016 - acc: 0.9502 - f1_m: 0.9427 - precision_m: 0.9578 - recall_m: 0.9287 - val_loss: 0.0073 - val_acc: 0.7416 - val_f1_m: 0.7447 - val_precision_m: 0.7785 - val_recall_m: 0.7146\n",
      "Epoch 182/250\n",
      "1139/1139 [==============================] - 1230s 1s/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9425 - precision_m: 0.9575 - recall_m: 0.9286 - val_loss: 0.0074 - val_acc: 0.7408 - val_f1_m: 0.7432 - val_precision_m: 0.7773 - val_recall_m: 0.7128\n",
      "Epoch 183/250\n",
      "1139/1139 [==============================] - 1204s 1s/step - loss: 0.0016 - acc: 0.9493 - f1_m: 0.9419 - precision_m: 0.9569 - recall_m: 0.9279 - val_loss: 0.0073 - val_acc: 0.7433 - val_f1_m: 0.7461 - val_precision_m: 0.7721 - val_recall_m: 0.7226\n",
      "Epoch 184/250\n",
      "1139/1139 [==============================] - 1192s 1s/step - loss: 0.0016 - acc: 0.9489 - f1_m: 0.9422 - precision_m: 0.9572 - recall_m: 0.9283 - val_loss: 0.0074 - val_acc: 0.7393 - val_f1_m: 0.7404 - val_precision_m: 0.7725 - val_recall_m: 0.7119\n",
      "Epoch 185/250\n",
      "1139/1139 [==============================] - 1189s 1s/step - loss: 0.0016 - acc: 0.9492 - f1_m: 0.9425 - precision_m: 0.9562 - recall_m: 0.9297 - val_loss: 0.0074 - val_acc: 0.7400 - val_f1_m: 0.7421 - val_precision_m: 0.7748 - val_recall_m: 0.7128\n",
      "Epoch 186/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0016 - acc: 0.9482 - f1_m: 0.9414 - precision_m: 0.9565 - recall_m: 0.9273 - val_loss: 0.0073 - val_acc: 0.7415 - val_f1_m: 0.7447 - val_precision_m: 0.7757 - val_recall_m: 0.7169\n",
      "Epoch 187/250\n",
      "1139/1139 [==============================] - 1793s 2s/step - loss: 0.0016 - acc: 0.9493 - f1_m: 0.9422 - precision_m: 0.9565 - recall_m: 0.9289 - val_loss: 0.0073 - val_acc: 0.7439 - val_f1_m: 0.7457 - val_precision_m: 0.7768 - val_recall_m: 0.7177\n",
      "Epoch 188/250\n",
      "1139/1139 [==============================] - 1161s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9419 - precision_m: 0.9566 - recall_m: 0.9282 - val_loss: 0.0074 - val_acc: 0.7418 - val_f1_m: 0.7423 - val_precision_m: 0.7695 - val_recall_m: 0.7177\n",
      "Epoch 189/250\n",
      "1139/1139 [==============================] - 1151s 1s/step - loss: 0.0016 - acc: 0.9491 - f1_m: 0.9425 - precision_m: 0.9569 - recall_m: 0.9291 - val_loss: 0.0076 - val_acc: 0.7400 - val_f1_m: 0.7392 - val_precision_m: 0.7582 - val_recall_m: 0.7220\n",
      "Epoch 190/250\n",
      "1139/1139 [==============================] - 1169s 1s/step - loss: 0.0016 - acc: 0.9486 - f1_m: 0.9412 - precision_m: 0.9558 - recall_m: 0.9277 - val_loss: 0.0075 - val_acc: 0.7428 - val_f1_m: 0.7437 - val_precision_m: 0.7643 - val_recall_m: 0.7251\n",
      "Epoch 191/250\n",
      "1139/1139 [==============================] - 1154s 1s/step - loss: 0.0016 - acc: 0.9492 - f1_m: 0.9425 - precision_m: 0.9567 - recall_m: 0.9293 - val_loss: 0.0074 - val_acc: 0.7439 - val_f1_m: 0.7439 - val_precision_m: 0.7739 - val_recall_m: 0.7170\n",
      "Epoch 192/250\n",
      "1139/1139 [==============================] - 1165s 1s/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9431 - precision_m: 0.9573 - recall_m: 0.9300 - val_loss: 0.0074 - val_acc: 0.7429 - val_f1_m: 0.7438 - val_precision_m: 0.7732 - val_recall_m: 0.7174\n",
      "Epoch 193/250\n",
      "1139/1139 [==============================] - 1195s 1s/step - loss: 0.0015 - acc: 0.9503 - f1_m: 0.9429 - precision_m: 0.9577 - recall_m: 0.9292 - val_loss: 0.0074 - val_acc: 0.7406 - val_f1_m: 0.7402 - val_precision_m: 0.7737 - val_recall_m: 0.7103\n",
      "Epoch 194/250\n",
      "1139/1139 [==============================] - 1197s 1s/step - loss: 0.0016 - acc: 0.9485 - f1_m: 0.9422 - precision_m: 0.9569 - recall_m: 0.9286 - val_loss: 0.0074 - val_acc: 0.7385 - val_f1_m: 0.7437 - val_precision_m: 0.7728 - val_recall_m: 0.7176\n",
      "Epoch 195/250\n",
      "1139/1139 [==============================] - 1220s 1s/step - loss: 0.0016 - acc: 0.9491 - f1_m: 0.9429 - precision_m: 0.9573 - recall_m: 0.9295 - val_loss: 0.0074 - val_acc: 0.7424 - val_f1_m: 0.7432 - val_precision_m: 0.7721 - val_recall_m: 0.7172\n",
      "Epoch 196/250\n",
      "1139/1139 [==============================] - 1410s 1s/step - loss: 0.0016 - acc: 0.9492 - f1_m: 0.9417 - precision_m: 0.9566 - recall_m: 0.9278 - val_loss: 0.0074 - val_acc: 0.7435 - val_f1_m: 0.7442 - val_precision_m: 0.7674 - val_recall_m: 0.7232\n",
      "Epoch 197/250\n",
      "1139/1139 [==============================] - 1218s 1s/step - loss: 0.0017 - acc: 0.9469 - f1_m: 0.9395 - precision_m: 0.9546 - recall_m: 0.9254 - val_loss: 0.0074 - val_acc: 0.7445 - val_f1_m: 0.7454 - val_precision_m: 0.7639 - val_recall_m: 0.7286\n",
      "Epoch 198/250\n",
      "1139/1139 [==============================] - 1211s 1s/step - loss: 0.0016 - acc: 0.9479 - f1_m: 0.9413 - precision_m: 0.9564 - recall_m: 0.9273 - val_loss: 0.0074 - val_acc: 0.7409 - val_f1_m: 0.7435 - val_precision_m: 0.7693 - val_recall_m: 0.7202\n",
      "Epoch 199/250\n",
      "1139/1139 [==============================] - 1215s 1s/step - loss: 0.0016 - acc: 0.9501 - f1_m: 0.9433 - precision_m: 0.9587 - recall_m: 0.9290 - val_loss: 0.0074 - val_acc: 0.7410 - val_f1_m: 0.7437 - val_precision_m: 0.7683 - val_recall_m: 0.7215\n",
      "Epoch 200/250\n",
      "1139/1139 [==============================] - 1210s 1s/step - loss: 0.0016 - acc: 0.9484 - f1_m: 0.9415 - precision_m: 0.9568 - recall_m: 0.9273 - val_loss: 0.0075 - val_acc: 0.7389 - val_f1_m: 0.7401 - val_precision_m: 0.7659 - val_recall_m: 0.7170\n",
      "Epoch 201/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0016 - acc: 0.9489 - f1_m: 0.9427 - precision_m: 0.9573 - recall_m: 0.9291 - val_loss: 0.0074 - val_acc: 0.7425 - val_f1_m: 0.7451 - val_precision_m: 0.7745 - val_recall_m: 0.7187\n",
      "Epoch 202/250\n",
      "1139/1139 [==============================] - 1185s 1s/step - loss: 0.0016 - acc: 0.9494 - f1_m: 0.9425 - precision_m: 0.9571 - recall_m: 0.9290 - val_loss: 0.0075 - val_acc: 0.7393 - val_f1_m: 0.7404 - val_precision_m: 0.7673 - val_recall_m: 0.7162\n",
      "Epoch 203/250\n",
      "1139/1139 [==============================] - 1203s 1s/step - loss: 0.0016 - acc: 0.9487 - f1_m: 0.9420 - precision_m: 0.9574 - recall_m: 0.9276 - val_loss: 0.0075 - val_acc: 0.7400 - val_f1_m: 0.7396 - val_precision_m: 0.7661 - val_recall_m: 0.7158\n",
      "Epoch 204/250\n",
      "1139/1139 [==============================] - 1196s 1s/step - loss: 0.0016 - acc: 0.9484 - f1_m: 0.9415 - precision_m: 0.9565 - recall_m: 0.9275 - val_loss: 0.0075 - val_acc: 0.7399 - val_f1_m: 0.7408 - val_precision_m: 0.7702 - val_recall_m: 0.7146\n",
      "Epoch 205/250\n",
      "1139/1139 [==============================] - 1186s 1s/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9423 - precision_m: 0.9560 - recall_m: 0.9296 - val_loss: 0.0074 - val_acc: 0.7411 - val_f1_m: 0.7420 - val_precision_m: 0.7716 - val_recall_m: 0.7155\n",
      "Epoch 206/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1195s 1s/step - loss: 0.0016 - acc: 0.9498 - f1_m: 0.9429 - precision_m: 0.9577 - recall_m: 0.9291 - val_loss: 0.0074 - val_acc: 0.7451 - val_f1_m: 0.7453 - val_precision_m: 0.7707 - val_recall_m: 0.7223\n",
      "Epoch 207/250\n",
      "1139/1139 [==============================] - 1195s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9418 - precision_m: 0.9573 - recall_m: 0.9273 - val_loss: 0.0074 - val_acc: 0.7411 - val_f1_m: 0.7435 - val_precision_m: 0.7761 - val_recall_m: 0.7145\n",
      "Epoch 208/250\n",
      "1139/1139 [==============================] - 1193s 1s/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9420 - precision_m: 0.9571 - recall_m: 0.9280 - val_loss: 0.0075 - val_acc: 0.7409 - val_f1_m: 0.7428 - val_precision_m: 0.7658 - val_recall_m: 0.7220\n",
      "Epoch 209/250\n",
      "1139/1139 [==============================] - 1212s 1s/step - loss: 0.0016 - acc: 0.9482 - f1_m: 0.9416 - precision_m: 0.9566 - recall_m: 0.9277 - val_loss: 0.0075 - val_acc: 0.7413 - val_f1_m: 0.7435 - val_precision_m: 0.7653 - val_recall_m: 0.7238\n",
      "Epoch 210/250\n",
      "1139/1139 [==============================] - 1191s 1s/step - loss: 0.0016 - acc: 0.9498 - f1_m: 0.9429 - precision_m: 0.9572 - recall_m: 0.9297 - val_loss: 0.0074 - val_acc: 0.7427 - val_f1_m: 0.7442 - val_precision_m: 0.7679 - val_recall_m: 0.7228\n",
      "Epoch 211/250\n",
      "1139/1139 [==============================] - 1197s 1s/step - loss: 0.0016 - acc: 0.9480 - f1_m: 0.9414 - precision_m: 0.9565 - recall_m: 0.9273 - val_loss: 0.0074 - val_acc: 0.7424 - val_f1_m: 0.7445 - val_precision_m: 0.7727 - val_recall_m: 0.7190\n",
      "Epoch 212/250\n",
      "1139/1139 [==============================] - 1202s 1s/step - loss: 0.0016 - acc: 0.9494 - f1_m: 0.9423 - precision_m: 0.9572 - recall_m: 0.9284 - val_loss: 0.0075 - val_acc: 0.7408 - val_f1_m: 0.7415 - val_precision_m: 0.7693 - val_recall_m: 0.7165\n",
      "Epoch 213/250\n",
      "1139/1139 [==============================] - 1175s 1s/step - loss: 0.0016 - acc: 0.9494 - f1_m: 0.9433 - precision_m: 0.9577 - recall_m: 0.9299 - val_loss: 0.0075 - val_acc: 0.7418 - val_f1_m: 0.7423 - val_precision_m: 0.7629 - val_recall_m: 0.7238\n",
      "Epoch 214/250\n",
      "1139/1139 [==============================] - 1180s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9422 - precision_m: 0.9570 - recall_m: 0.9284 - val_loss: 0.0074 - val_acc: 0.7423 - val_f1_m: 0.7438 - val_precision_m: 0.7704 - val_recall_m: 0.7199\n",
      "Epoch 215/250\n",
      "1139/1139 [==============================] - 1171s 1s/step - loss: 0.0016 - acc: 0.9499 - f1_m: 0.9427 - precision_m: 0.9571 - recall_m: 0.9294 - val_loss: 0.0075 - val_acc: 0.7398 - val_f1_m: 0.7411 - val_precision_m: 0.7649 - val_recall_m: 0.7196\n",
      "Epoch 216/250\n",
      "1139/1139 [==============================] - 1172s 1s/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9423 - precision_m: 0.9562 - recall_m: 0.9294 - val_loss: 0.0074 - val_acc: 0.7418 - val_f1_m: 0.7444 - val_precision_m: 0.7663 - val_recall_m: 0.7245\n",
      "Epoch 217/250\n",
      "1139/1139 [==============================] - 1193s 1s/step - loss: 0.0016 - acc: 0.9497 - f1_m: 0.9436 - precision_m: 0.9577 - recall_m: 0.9305 - val_loss: 0.0073 - val_acc: 0.7428 - val_f1_m: 0.7446 - val_precision_m: 0.7762 - val_recall_m: 0.7164\n",
      "Epoch 218/250\n",
      "1139/1139 [==============================] - 1222s 1s/step - loss: 0.0016 - acc: 0.9496 - f1_m: 0.9428 - precision_m: 0.9574 - recall_m: 0.9292 - val_loss: 0.0074 - val_acc: 0.7416 - val_f1_m: 0.7437 - val_precision_m: 0.7712 - val_recall_m: 0.7190\n",
      "Epoch 219/250\n",
      "1139/1139 [==============================] - 1194s 1s/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9425 - precision_m: 0.9571 - recall_m: 0.9287 - val_loss: 0.0074 - val_acc: 0.7441 - val_f1_m: 0.7443 - val_precision_m: 0.7670 - val_recall_m: 0.7239\n",
      "Epoch 220/250\n",
      "1139/1139 [==============================] - 1202s 1s/step - loss: 0.0016 - acc: 0.9499 - f1_m: 0.9426 - precision_m: 0.9565 - recall_m: 0.9297 - val_loss: 0.0076 - val_acc: 0.7413 - val_f1_m: 0.7415 - val_precision_m: 0.7585 - val_recall_m: 0.7260\n",
      "Epoch 221/250\n",
      "1139/1139 [==============================] - 1192s 1s/step - loss: 0.0016 - acc: 0.9502 - f1_m: 0.9429 - precision_m: 0.9578 - recall_m: 0.9291 - val_loss: 0.0075 - val_acc: 0.7359 - val_f1_m: 0.7394 - val_precision_m: 0.7656 - val_recall_m: 0.7160\n",
      "Epoch 222/250\n",
      "1139/1139 [==============================] - 1176s 1s/step - loss: 0.0016 - acc: 0.9485 - f1_m: 0.9418 - precision_m: 0.9568 - recall_m: 0.9279 - val_loss: 0.0074 - val_acc: 0.7409 - val_f1_m: 0.7437 - val_precision_m: 0.7765 - val_recall_m: 0.7143\n",
      "Epoch 223/250\n",
      "1139/1139 [==============================] - 1810s 2s/step - loss: 0.0016 - acc: 0.9488 - f1_m: 0.9421 - precision_m: 0.9569 - recall_m: 0.9283 - val_loss: 0.0075 - val_acc: 0.7378 - val_f1_m: 0.7390 - val_precision_m: 0.7657 - val_recall_m: 0.7150\n",
      "Epoch 224/250\n",
      "1139/1139 [==============================] - 1113s 977ms/step - loss: 0.0016 - acc: 0.9497 - f1_m: 0.9438 - precision_m: 0.9582 - recall_m: 0.9304 - val_loss: 0.0075 - val_acc: 0.7445 - val_f1_m: 0.7456 - val_precision_m: 0.7653 - val_recall_m: 0.7278\n",
      "Epoch 225/250\n",
      "1139/1139 [==============================] - 1114s 978ms/step - loss: 0.0016 - acc: 0.9483 - f1_m: 0.9416 - precision_m: 0.9571 - recall_m: 0.9272 - val_loss: 0.0074 - val_acc: 0.7429 - val_f1_m: 0.7450 - val_precision_m: 0.7738 - val_recall_m: 0.7192\n",
      "Epoch 226/250\n",
      "1139/1139 [==============================] - 1140s 1s/step - loss: 0.0016 - acc: 0.9491 - f1_m: 0.9417 - precision_m: 0.9562 - recall_m: 0.9283 - val_loss: 0.0075 - val_acc: 0.7431 - val_f1_m: 0.7429 - val_precision_m: 0.7696 - val_recall_m: 0.7189\n",
      "Epoch 227/250\n",
      "1139/1139 [==============================] - 1126s 989ms/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9426 - precision_m: 0.9569 - recall_m: 0.9292 - val_loss: 0.0075 - val_acc: 0.7419 - val_f1_m: 0.7447 - val_precision_m: 0.7653 - val_recall_m: 0.7260\n",
      "Epoch 228/250\n",
      "1139/1139 [==============================] - 1120s 983ms/step - loss: 0.0016 - acc: 0.9494 - f1_m: 0.9420 - precision_m: 0.9575 - recall_m: 0.9277 - val_loss: 0.0075 - val_acc: 0.7422 - val_f1_m: 0.7431 - val_precision_m: 0.7646 - val_recall_m: 0.7237\n",
      "Epoch 229/250\n",
      "1139/1139 [==============================] - 1117s 981ms/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9428 - precision_m: 0.9572 - recall_m: 0.9293 - val_loss: 0.0075 - val_acc: 0.7392 - val_f1_m: 0.7408 - val_precision_m: 0.7663 - val_recall_m: 0.7179\n",
      "Epoch 230/250\n",
      "1139/1139 [==============================] - 1123s 986ms/step - loss: 0.0016 - acc: 0.9499 - f1_m: 0.9436 - precision_m: 0.9575 - recall_m: 0.9307 - val_loss: 0.0075 - val_acc: 0.7437 - val_f1_m: 0.7454 - val_precision_m: 0.7663 - val_recall_m: 0.7265\n",
      "Epoch 231/250\n",
      "1139/1139 [==============================] - 1124s 987ms/step - loss: 0.0016 - acc: 0.9489 - f1_m: 0.9417 - precision_m: 0.9563 - recall_m: 0.9281 - val_loss: 0.0074 - val_acc: 0.7418 - val_f1_m: 0.7432 - val_precision_m: 0.7690 - val_recall_m: 0.7198\n",
      "Epoch 232/250\n",
      "1139/1139 [==============================] - 1132s 994ms/step - loss: 0.0016 - acc: 0.9498 - f1_m: 0.9424 - precision_m: 0.9571 - recall_m: 0.9287 - val_loss: 0.0075 - val_acc: 0.7427 - val_f1_m: 0.7438 - val_precision_m: 0.7637 - val_recall_m: 0.7257\n",
      "Epoch 233/250\n",
      "1139/1139 [==============================] - 1131s 993ms/step - loss: 0.0016 - acc: 0.9498 - f1_m: 0.9434 - precision_m: 0.9571 - recall_m: 0.9308 - val_loss: 0.0075 - val_acc: 0.7425 - val_f1_m: 0.7433 - val_precision_m: 0.7676 - val_recall_m: 0.7213\n",
      "Epoch 234/250\n",
      "1139/1139 [==============================] - 1130s 992ms/step - loss: 0.0016 - acc: 0.9496 - f1_m: 0.9435 - precision_m: 0.9583 - recall_m: 0.9298 - val_loss: 0.0075 - val_acc: 0.7405 - val_f1_m: 0.7420 - val_precision_m: 0.7674 - val_recall_m: 0.7192\n",
      "Epoch 235/250\n",
      "1139/1139 [==============================] - 1122s 986ms/step - loss: 0.0016 - acc: 0.9502 - f1_m: 0.9440 - precision_m: 0.9588 - recall_m: 0.9302 - val_loss: 0.0074 - val_acc: 0.7420 - val_f1_m: 0.7442 - val_precision_m: 0.7731 - val_recall_m: 0.7183\n",
      "Epoch 236/250\n",
      "1139/1139 [==============================] - 1124s 987ms/step - loss: 0.0016 - acc: 0.9491 - f1_m: 0.9431 - precision_m: 0.9578 - recall_m: 0.9295 - val_loss: 0.0076 - val_acc: 0.7411 - val_f1_m: 0.7421 - val_precision_m: 0.7577 - val_recall_m: 0.7281\n",
      "Epoch 237/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139/1139 [==============================] - 1133s 995ms/step - loss: 0.0016 - acc: 0.9485 - f1_m: 0.9411 - precision_m: 0.9564 - recall_m: 0.9270 - val_loss: 0.0075 - val_acc: 0.7411 - val_f1_m: 0.7428 - val_precision_m: 0.7659 - val_recall_m: 0.7219\n",
      "Epoch 238/250\n",
      "1139/1139 [==============================] - 1134s 995ms/step - loss: 0.0016 - acc: 0.9489 - f1_m: 0.9425 - precision_m: 0.9567 - recall_m: 0.9293 - val_loss: 0.0075 - val_acc: 0.7401 - val_f1_m: 0.7410 - val_precision_m: 0.7689 - val_recall_m: 0.7159\n",
      "Epoch 239/250\n",
      "1139/1139 [==============================] - 1119s 983ms/step - loss: 0.0016 - acc: 0.9486 - f1_m: 0.9416 - precision_m: 0.9562 - recall_m: 0.9281 - val_loss: 0.0075 - val_acc: 0.7428 - val_f1_m: 0.7432 - val_precision_m: 0.7690 - val_recall_m: 0.7200\n",
      "Epoch 240/250\n",
      "1139/1139 [==============================] - 1126s 989ms/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9422 - precision_m: 0.9580 - recall_m: 0.9276 - val_loss: 0.0075 - val_acc: 0.7415 - val_f1_m: 0.7418 - val_precision_m: 0.7724 - val_recall_m: 0.7143\n",
      "Epoch 241/250\n",
      "1139/1139 [==============================] - 1141s 1s/step - loss: 0.0016 - acc: 0.9481 - f1_m: 0.9420 - precision_m: 0.9572 - recall_m: 0.9279 - val_loss: 0.0076 - val_acc: 0.7394 - val_f1_m: 0.7391 - val_precision_m: 0.7577 - val_recall_m: 0.7223\n",
      "Epoch 242/250\n",
      "1139/1139 [==============================] - 1132s 994ms/step - loss: 0.0016 - acc: 0.9484 - f1_m: 0.9406 - precision_m: 0.9549 - recall_m: 0.9274 - val_loss: 0.0075 - val_acc: 0.7420 - val_f1_m: 0.7427 - val_precision_m: 0.7651 - val_recall_m: 0.7224\n",
      "Epoch 243/250\n",
      "1139/1139 [==============================] - 1143s 1s/step - loss: 0.0017 - acc: 0.9471 - f1_m: 0.9396 - precision_m: 0.9536 - recall_m: 0.9265 - val_loss: 0.0075 - val_acc: 0.7392 - val_f1_m: 0.7427 - val_precision_m: 0.7676 - val_recall_m: 0.7202\n",
      "Epoch 244/250\n",
      "1139/1139 [==============================] - 1141s 1s/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9435 - precision_m: 0.9579 - recall_m: 0.9301 - val_loss: 0.0075 - val_acc: 0.7416 - val_f1_m: 0.7430 - val_precision_m: 0.7658 - val_recall_m: 0.7224\n",
      "Epoch 245/250\n",
      "1139/1139 [==============================] - 1116s 980ms/step - loss: 0.0016 - acc: 0.9503 - f1_m: 0.9434 - precision_m: 0.9587 - recall_m: 0.9291 - val_loss: 0.0075 - val_acc: 0.7430 - val_f1_m: 0.7452 - val_precision_m: 0.7649 - val_recall_m: 0.7271\n",
      "Epoch 246/250\n",
      "1139/1139 [==============================] - 1127s 989ms/step - loss: 0.0016 - acc: 0.9492 - f1_m: 0.9427 - precision_m: 0.9572 - recall_m: 0.9292 - val_loss: 0.0075 - val_acc: 0.7431 - val_f1_m: 0.7439 - val_precision_m: 0.7651 - val_recall_m: 0.7244\n",
      "Epoch 247/250\n",
      "1139/1139 [==============================] - 1122s 985ms/step - loss: 0.0016 - acc: 0.9484 - f1_m: 0.9425 - precision_m: 0.9573 - recall_m: 0.9287 - val_loss: 0.0075 - val_acc: 0.7442 - val_f1_m: 0.7450 - val_precision_m: 0.7601 - val_recall_m: 0.7312\n",
      "Epoch 248/250\n",
      "1139/1139 [==============================] - 1130s 992ms/step - loss: 0.0016 - acc: 0.9497 - f1_m: 0.9433 - precision_m: 0.9575 - recall_m: 0.9302 - val_loss: 0.0074 - val_acc: 0.7429 - val_f1_m: 0.7441 - val_precision_m: 0.7730 - val_recall_m: 0.7181\n",
      "Epoch 249/250\n",
      "1139/1139 [==============================] - 1130s 992ms/step - loss: 0.0016 - acc: 0.9495 - f1_m: 0.9428 - precision_m: 0.9576 - recall_m: 0.9289 - val_loss: 0.0075 - val_acc: 0.7414 - val_f1_m: 0.7428 - val_precision_m: 0.7699 - val_recall_m: 0.7184\n",
      "Epoch 250/250\n",
      "1139/1139 [==============================] - 1108s 973ms/step - loss: 0.0016 - acc: 0.9490 - f1_m: 0.9423 - precision_m: 0.9568 - recall_m: 0.9289 - val_loss: 0.0075 - val_acc: 0.7424 - val_f1_m: 0.7436 - val_precision_m: 0.7690 - val_recall_m: 0.7208\n"
     ]
    }
   ],
   "source": [
    "# CNN Bilstm attention\n",
    "from keras.layers import Input, Dense, LSTM, concatenate,Conv1D,Dropout,Bidirectional,Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Attention\n",
    "from keras.layers.core import *\n",
    "from keras.models import *\n",
    "\n",
    "lstm_units = 64\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = inputs\n",
    "    #a = Permute((2, 1))(inputs)\n",
    "    #a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(input_dim, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((1, 2), name='attention_vec')(a)\n",
    "\n",
    "    output_attention_mul = concatenate([inputs, a_probs])\n",
    "    return output_attention_mul\n",
    "\n",
    "def attention_model():\n",
    "#     inputs = Input(shape= x_train.shape)\n",
    "\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    \n",
    "    x = Conv1D(filters = 128, kernel_size = 5, activation = 'relu')(embedded_sequences)  #, padding = 'same'\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "#     lstm_out = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "#     lstm_out = Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.2, activation = 'tanh'))(x)\n",
    "    lstm_out = Bidirectional(LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "#     lstm_out = Dropout(0.3)(lstm_out)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "        \n",
    "    output = Dense(63, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[sequence_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "m = attention_model()\n",
    "m.summary()\n",
    "m.compile(optimizer='adam', loss='mse', metrics=['acc', f1_m, precision_m, recall_m])\n",
    "history = m.fit([x_train], y_train, epochs=250, batch_size=64, validation_split=0.3, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f3864d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLstm CNN Model \n",
    "# from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "# from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "# x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "# x = SpatialDropout1D(0.2)(x)\n",
    "# x = Bidirectional(LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "# x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "# avg_pool = GlobalAveragePooling1D()(x)\n",
    "# max_pool = GlobalMaxPooling1D()(x)\n",
    "# x = concatenate([avg_pool, max_pool]) \n",
    "# # x = Dense(128, activation='relu')(x)\n",
    "# # x = Dropout(0.1)(x)\n",
    "# preds = Dense(63, activation=\"sigmoid\")(x)\n",
    "# model = Model(sequence_input, preds)\n",
    "# model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])\n",
    "# model.summary()\n",
    "# history = model.fit(x_train, y_train, epochs = 20, validation_split=0.1, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a29f4de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot metrics\n",
    "pyplot.plot(history.history[\"f1_m\"],  label=\"f1 score\")\n",
    "\n",
    "pyplot.plot(history.history[\"recall_m\"], label=\"recall\")\n",
    "pyplot.plot(history.history['acc'] , label=\"accuracy\")\n",
    "pyplot.title('Evaluation stats')\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b282e234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = m.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfb7e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 74.23%\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "from keras.models import model_from_json \n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835dd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f9748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35c784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cb577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d52f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da66203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20825cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
