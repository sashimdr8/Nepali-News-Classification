{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0974d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project dependencies\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score,\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.manifold import TSNE \n",
    "\n",
    "# NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import  word_tokenize\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras import backend as K\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.layers.core import *\n",
    "from keras.models import *\n",
    "from keras.layers import LSTM, concatenate,Bidirectional,Multiply\n",
    "\n",
    "#Seq2Seq\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.layers import Attention\n",
    "\n",
    "# Matplotlib\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other dependencies\n",
    "from scipy import spatial\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2fab0775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape: (104047, 5)\n",
      "Row Size: 104047\n",
      "Column Size: 5\n"
     ]
    }
   ],
   "source": [
    "# Read csv dataset and save to df\n",
    "\n",
    "filePath = 'TOTAL_TEXTS_SETOPATI.csv'\n",
    "df = pd.read_csv(filePath)\n",
    "\n",
    "# Define Constant Variables\n",
    "VALIDATION_SPLIT = 0.1\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "# computing number of rows\n",
    "rows = len(df.axes[0])\n",
    " \n",
    "# computing number of columns\n",
    "cols = len(df.axes[1])\n",
    "print(\"DataFrame Shape: \"+ str(df.shape))\n",
    "print(\"Row Size: \"+ str(rows))\n",
    "print(\"Column Size: \"+ str(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7a79251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing\n",
      "\n",
      "\\n\\tकाठमाडौंको कीर्तिपुर क्रिकेट मैदानमा भोलि हुने नेपाल र नामिवियाबीचको खेलमा नेपाल प्रहरीले सुरक्षाका लागि प्रहरी उपरीक्षकको कमाण्डमा ७ सय ७३ जना प्रहरी परिचालन गर्ने भएको छ।\\n\\n\\t\\xa0\\n\\n\\tमहानगरीय प्रहरी कार्यालय रानीपोखरीले शुक्रबार पत्रकार सम्मेलन गरेर काठमाडौं प्रहरी परिसरका एसपी प्रद्युम्न कार्कीको कमाण्डमा ७ सय ७३ जना प्रहरी परिचालन गर्ने एआईजी प्रतापसिंह थापाले जानकारी दिए।\\xa0\\n\\n\\t\\xa0\\n\\n\\tथापाका अनुसार सादा पोशाकमा पनि प्रहरी परिचालन गरिनेछ। नेपाल प्रहरीको साथै खेल मैदानमा सशस्त्र प्रहरी बलका सय भन्दा बढी प्रहरी पनि परिचालन हुने भएको छ।थप आवश्यक परे सशस्त्र प्रहरी अरु पनि खटाउन सकिने सशस्त्र प्रहरीका प्रवक्ता डिआइजी शैलेन्द्र खनालले बताए। क्रिकेट मैदानसँगै भित्र पट्टि नेपाल प्रहरीको एक घेरा हुनेछ भने त्यसपछि दर्शकमाझ र दर्शकबाहिर गरी ३ घेरा राखिने प्रहरीले बताएको छ। \\xa0\\n\\n\\t\\xa0\\n\\n\\tनेपाल प्रहरीको घेराबाहिर सशस्त्र प्रहरीले पनि मैदानलाई सुरक्षा दिने प्रहरीले बताएको छ। अन्तर्राष्ट्रियस्तरको खेल भएकाले सुरक्षा पनि अन्तर्राष्ट्रियस्तरकै हुने एआईजी थापाले बताए। खेलाडीहरुलाई होटलदेखि मैदानसम्मको सुरक्षा गर्ने जिम्मा पनि प्रहरीलाई नै दिइएको छ ।\\n\\n\\t\\xa0\\n\\n\\tनेपालमा अन्तर्राष्ट्रियस्तरको सुरक्षा प्रदान गर्न आईसीसीले नै पत्र पठाएपछि महानगरीय प्रहरी कार्यालय रानीपोखरीले लिखित रुपमा मैदानमा अपनाइने सुरक्षाका बारेमा लेखेर पठाएको छ। साथै मैदानको सुरक्षाका लागि \\xa0सीसीटीभी जडान गरिएको छ। मेडल डिरेक्टर \\xa0र वाक थ्रु गेट जडान गरिएको छ।\\xa0\\n\\n\\t\\xa0\\n\\n\\tदर्शक निगरानी र सुरक्षाका लागि विशेष सुरक्षा अपनाइएको एआईजी थापाले बताए। कीर्तिपुर क्रिकेट मैदान १५ हजार दर्शक क्षमताको छ। \\xa0खेल अवधिभर उछृङ्खल गतिविधि नगर्न प्रहरीले सबै खेलप्रेमीसँग आग्रह गरेको छ। दर्शकहरुलाई सीसाद्वारा बनेको सामान लैजान पनि प्रतिबन्ध लगाइएको छ।\\xa0\\n\\n\\t\n",
      "After preprocessing\n",
      "\n",
      "काठमाडौंको कीर्तिपुर क्रिकेट मैदानमा भोलि नेपाल नामिवियाबीचको खेलमा नेपाल प्रहरीले सुरक्षाका प्रहरी उपरीक्षकको कमाण्डमा ७ सय ७३ जना प्रहरी परिचालन छमहानगरीय प्रहरी कार्यालय रानीपोखरीले शुक्रबार पत्रकार सम्मेलन काठमाडौं प्रहरी परिसरका एसपी प्रद्युम्न कार्कीको कमाण्डमा ७ सय ७३ जना प्रहरी परिचालन एआईजी प्रतापसिंह थापाले जानकारी दिएथापाका सादा पोशाकमा प्रहरी परिचालन गरिनेछ नेपाल प्रहरीको खेल मैदानमा सशस्त्र प्रहरी बलका सय बढी प्रहरी परिचालन छथप आवश्यक परे सशस्त्र प्रहरी खटाउन सकिने सशस्त्र प्रहरीका प्रवक्ता डिआइजी शैलेन्द्र खनालले बताए क्रिकेट मैदानसँगै पट्टि नेपाल प्रहरीको घेरा हुनेछ त्यसपछि दर्शकमाझ दर्शकबाहिर ३ घेरा राखिने प्रहरीले बताएको नेपाल प्रहरीको घेराबाहिर सशस्त्र प्रहरीले मैदानलाई सुरक्षा दिने प्रहरीले बताएको अन्तर्राष्ट्रियस्तरको खेल भएकाले सुरक्षा अन्तर्राष्ट्रियस्तरकै एआईजी थापाले बताए खेलाडीहरुलाई होटलदेखि मैदानसम्मको सुरक्षा जिम्मा प्रहरीलाई दिइएको नेपालमा अन्तर्राष्ट्रियस्तरको सुरक्षा प्रदान आईसीसीले पत्र पठाएपछि महानगरीय प्रहरी कार्यालय रानीपोखरीले लिखित रुपमा मैदानमा अपनाइने सुरक्षाका बारेमा लेखेर पठाएको मैदानको सुरक्षाका सीसीटीभी जडान गरिएको मेडल डिरेक्टर वाक थ्रु गेट जडान गरिएको छदर्शक निगरानी सुरक्षाका विशेष सुरक्षा अपनाइएको एआईजी थापाले बताए कीर्तिपुर क्रिकेट मैदान १५ हजार दर्शक क्षमताको खेल अवधिभर उछृङ्खल गतिविधि नगर्न प्रहरीले खेलप्रेमीसँग आग्रह दर्शकहरुलाई सीसाद्वारा बनेको सामान लैजान प्रतिबन्ध लगाइएको\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing {Remove Stop words using nltk}\n",
    "\n",
    "stop_words = stopwords.words(\"nepali\")\n",
    "def string_manipulation(df,column)  : \n",
    "    df[column] = df[column].apply(remove_special_characters)\n",
    "    df[column] = df[column].apply(remove_non_useful_characters)\n",
    "    df[column] = df[column].apply(lambda x: \" \".join([i for i in x.split()if i not in (stop_words)]))\n",
    "    return df\n",
    "\n",
    "def remove_special_characters(input_string):\n",
    "    return re.sub('[।(),<<?!,—,–,/,’,‘,:,\\u200d]', '', input_string)\n",
    "\n",
    "def remove_non_useful_characters(input_string):\n",
    "    return re.sub(r'[^\\u0900-\\u097F\\s]', '', input_string)\n",
    "\n",
    "print(\"Before preprocessing\\n\")\n",
    "print(df[\"text\"][1])\n",
    "Data = string_manipulation(df,\"text\")\n",
    "print(\"After preprocessing\\n\")\n",
    "print(Data[\"text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "932f2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 663564 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# convert word into vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "embeddings_dict = {}\n",
    "\n",
    "# Used NPVec1: Word Embeddings for Nepali for glove from [https://github.com/nowalab/nepali-word-embeddings]\n",
    "# processed.glove.txt, processed_normalized_stemmed.glove \n",
    "\n",
    "with open(\"processed.glove\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        token = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[token] = vector\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "36b0ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "41fd1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104047 news texts.\n",
      "Categories with label ids:\n",
      " {'new-news': 0, 'archive-news': 1, 'politics': 2, 'sports': 3, 'sports/anya-khelkud': 4, 'sports/cricket': 5, 'sports/football': 6, 'sports/noc': 7, 'sports/sports-activity': 8, 'sports/volleyball': 9, 'art': 10, 'art/art-activity': 11, 'blog': 12, 'ghumphir/ghumphir-activity': 13, 'ghumphir/ghumphir-experience': 14, 'ghumphir/ghumphir-news': 15, 'global': 16, 'global/america': 17, 'global/asia': 18, 'global/australia': 19, 'global/belgium': 20, 'global/canada': 21, 'global/china': 22, 'global/denmark': 23, 'global/france': 24, 'global/india': 25, 'global/japan': 26, 'global/jeneva': 27, 'global/korea': 28, 'global/malaysia': 29, 'global/norway': 30, 'global/other-global': 31, 'global/portugal': 32, 'global/qatar': 33, 'global/saudi-arabia': 34, 'global/uae': 35, 'global/uk': 36, 'kinmel': 37, 'kinmel/agriculture': 38, 'kinmel/automobiles': 39, 'kinmel/banking': 40, 'kinmel/business': 41, 'kinmel/construction': 42, 'kinmel/employment': 43, 'kinmel/household': 44, 'kinmel/information-technology': 45, 'kinmel/jewellery': 46, 'kinmel/kinmel-experience': 47, 'kinmel/medical': 48, 'kinmel/others': 49, 'literature': 50, 'opinion': 51, 'social': 52, 'sports/South-Asian-Games': 53, 'art/blog-review': 54, 'art/bollywood': 55, 'art/book': 56, 'art/gossip': 57, 'art/hollywood': 58, 'art/interview': 59, 'art/ranga-manch': 60, 'general-news': 61, 'nepali-brand': 62}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catagory</th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new-news</td>\n",
       "      <td>मेसीलाई तुरुन्त अनुबन्धित गर्न बार्सिलोनालाई न...</td>\n",
       "      <td>ब्राजिलका स्टार स्ट्राइकर नेइमारले अर्जेन्टिनी...</td>\n",
       "      <td>बुधबार, वैशाख २७, २०७४, ००:४२:२९</td>\n",
       "      <td>https://dev.setoparty.com/new-news/45151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>archive-news</td>\n",
       "      <td>नेपाल र नामिबियाबीचको खेलमा यस्तो छ सुरक्षा</td>\n",
       "      <td>काठमाडौंको कीर्तिपुर क्रिकेट मैदानमा भोलि नेपा...</td>\n",
       "      <td>2016-04-15 16:41:04</td>\n",
       "      <td>https://dev.setoparty.com/archive-news/45151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>अलबिदा मणी शाह (भिडियो र फोटोफिचर)</td>\n",
       "      <td>नेपाली राष्ट्रिय फुटबल टोलीका खेलाडी मणी विक्र...</td>\n",
       "      <td>मंगलबार, जेठ १, २०७५, ०३:०५:४२</td>\n",
       "      <td>https://dev.setoparty.com/politics/158282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>मलेसियालाई १० विकेटले हराउँदै नेपाल एसिया कपमा...</td>\n",
       "      <td>मलेसियालाई १० विकेटको फराकिलो अन्तरमा हराउँदै ...</td>\n",
       "      <td>शनिबार, भदौ ३१, २०७४, ०३:२२:४७</td>\n",
       "      <td>https://dev.setoparty.com/politics/87233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>अर्धसतक पूरा गर्दै अाउट भए ज्ञानेन्द्र</td>\n",
       "      <td>विश्व क्रिकेट लिग डब्लुसिएल च्याम्पियनसिप नेपा...</td>\n",
       "      <td>बुधबार, मंसिर २०, २०७४, ०२:११:१६</td>\n",
       "      <td>https://dev.setoparty.com/sports/111454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       catagory                                            heading  \\\n",
       "0      new-news  मेसीलाई तुरुन्त अनुबन्धित गर्न बार्सिलोनालाई न...   \n",
       "1  archive-news        नेपाल र नामिबियाबीचको खेलमा यस्तो छ सुरक्षा   \n",
       "2      politics                 अलबिदा मणी शाह (भिडियो र फोटोफिचर)   \n",
       "3      politics  मलेसियालाई १० विकेटले हराउँदै नेपाल एसिया कपमा...   \n",
       "4        sports             अर्धसतक पूरा गर्दै अाउट भए ज्ञानेन्द्र   \n",
       "\n",
       "                                                text  \\\n",
       "0  ब्राजिलका स्टार स्ट्राइकर नेइमारले अर्जेन्टिनी...   \n",
       "1  काठमाडौंको कीर्तिपुर क्रिकेट मैदानमा भोलि नेपा...   \n",
       "2  नेपाली राष्ट्रिय फुटबल टोलीका खेलाडी मणी विक्र...   \n",
       "3  मलेसियालाई १० विकेटको फराकिलो अन्तरमा हराउँदै ...   \n",
       "4  विश्व क्रिकेट लिग डब्लुसिएल च्याम्पियनसिप नेपा...   \n",
       "\n",
       "                               date  \\\n",
       "0  बुधबार, वैशाख २७, २०७४, ००:४२:२९   \n",
       "1               2016-04-15 16:41:04   \n",
       "2    मंगलबार, जेठ १, २०७५, ०३:०५:४२   \n",
       "3    शनिबार, भदौ ३१, २०७४, ०३:२२:४७   \n",
       "4  बुधबार, मंसिर २०, २०७४, ०२:११:१६   \n",
       "\n",
       "                                           link  \n",
       "0      https://dev.setoparty.com/new-news/45151  \n",
       "1  https://dev.setoparty.com/archive-news/45151  \n",
       "2     https://dev.setoparty.com/politics/158282  \n",
       "3      https://dev.setoparty.com/politics/87233  \n",
       "4       https://dev.setoparty.com/sports/111454  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare text samples and their labels\n",
    "\n",
    "newsTexts = Data['text'].tolist()\n",
    "labels_map = {}  # dictionary mapping label name to numeric id\n",
    "labels = [] # list of label ids\n",
    "allCategoryDataList = Data['catagory']\n",
    "\n",
    "indexCount = 0\n",
    "for category in allCategoryDataList.unique():\n",
    "    labels_map[category] = indexCount\n",
    "    indexCount = indexCount + 1\n",
    "\n",
    "for category in allCategoryDataList.tolist():\n",
    "    labels.append(labels_map[category])\n",
    "        \n",
    "print('Found %s news texts.' % len(newsTexts))\n",
    "print('Categories with label ids:\\n %s' % labels_map)\n",
    "display(df.loc[0:4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2a0d6014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 874272 unique tokens.\n",
      "बताए: 1\n",
      "काम: 2\n",
      "गरिएको: 3\n",
      "नेपाल: 4\n",
      "हजार: 5\n"
     ]
    }
   ],
   "source": [
    "# Prepare word tokens to numeric value\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(newsTexts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "def printWordIndex(limit): \n",
    "    counter = 0\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if counter < limit:\n",
    "            print(f\"{word}: {index}\")\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "printWordIndex(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8058d036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (104047, 1000)\n",
      "Shape of label tensor: (104047, 63)\n",
      "\n",
      "\n",
      "First Label (Numpy Array): [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "\n",
      "Second Label (Numpy Array): [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Prepare text sequences\n",
    "sequences = tokenizer.texts_to_sequences(newsTexts)\n",
    "\n",
    "# helps to shortens the sequence to specified max length\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# convert list of class labels to a binary class matrix\n",
    "labelsCategorical = to_categorical(np.asarray(labels))\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labelsCategorical.shape)\n",
    "print(\"\\n\")\n",
    "print('First Label (Numpy Array):', labelsCategorical[0])\n",
    "print(\"\\n\")\n",
    "print('Second Label (Numpy Array):', labelsCategorical[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ab071ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      1      2 ... 104044 104045 104046]\n",
      "X train shape:  (93643, 1000)\n",
      "Y train shape:  (93643, 63)\n",
      "X test shape:  (10404, 1000)\n",
      "Y test shape:  (10404, 63)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "print(indices)\n",
    "\n",
    "#Shuffle dataset into random order\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "finalLabels = labelsCategorical[indices]\n",
    "\n",
    "# split the data into a training set(90%) and a validation set(10%)\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "# train news text and category set\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = finalLabels[:-num_validation_samples]\n",
    "\n",
    "# test news text and category set\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = finalLabels[-num_validation_samples:]\n",
    "\n",
    "print(\"X train shape: \", x_train.shape)\n",
    "print(\"Y train shape: \", y_train.shape)\n",
    "print(\"X test shape: \", x_val.shape)\n",
    "print(\"Y test shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load json and create model\n",
    "# # from keras.models import model_from_json \n",
    "# from tensorflow.keras.models import Sequential, model_from_json\n",
    "# from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json, custom_objects={'SeqSelfAttention': SeqSelfAttention})\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    " \n",
    "# # evaluate loaded model on test data\n",
    "# # loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "# loaded_model.compile(optimizer='adam', loss='mse', metrics=['acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "# score = loaded_model.evaluate(x_val, y_val, verbose=0)\n",
    "# index = 0\n",
    "# for metric in loaded_model.metrics_names:\n",
    "#     print(\"%s: %.2f%%\" % (metric, score[index]*100))\n",
    "#     index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "50ed6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Embedding Layer\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Embedding Layer\")\n",
    "# Get maximum number of words \n",
    "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
    "\n",
    "# Creates numpy array of shape (num_words, EMBEDDING_DIM)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "# Map each word token to vector using pre-trained embedding dictionary\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training model. CNN CNN Model.')\n",
    "\n",
    "# # train a 1D convnet with global maxpooling\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "# embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "# x1 = Dropout(0.2)(x)\n",
    "# x2 = MaxPooling1D(5)(x1)\n",
    "# x3 = Conv1D(128, 5, activation='relu')(x2)\n",
    "# x4 = Dropout(0.3)(x3)\n",
    "# x5 = MaxPooling1D(5)(x4)\n",
    "# x6 = Conv1D(128, 5, activation='relu')(x5)\n",
    "# x7 = GlobalMaxPooling1D()(x6)\n",
    "# x8 = Dense(128, activation='relu')(x7)\n",
    "# print(\"len labels:\", str(len(labels_index)))\n",
    "# preds = Dense(len(labels_index), activation='softmax')(x8)\n",
    "\n",
    "# print(\"Preds shape: \", preds.shape)\n",
    "# print(\"sequence_input shape: \", sequence_input.shape)\n",
    "\n",
    "# model = Model(sequence_input, preds)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "# print(\"Shape of x_train: \", x_train.shape)\n",
    "# print(\"Shape of y_train: \", y_train.shape)\n",
    "# print(\"Shape of x_val: \", x_val.shape)\n",
    "# print(\"Shape of y_val: \", y_val.shape)\n",
    "# print(model.output_shape)\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# history = model.fit(x_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=15,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training model. CNN biLstm Model.')\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding\n",
    "# from tensorflow.keras.layers import Bidirectional\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Activation\n",
    "# from keras.layers import Flatten\n",
    "\n",
    "\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "# embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(embedding_layer)\n",
    "# model.add(Conv1D(128, 5, activation='relu'))\n",
    "# model.add(MaxPooling1D(5))\n",
    "# model.add(Dropout(0.2)) # embedding dropouts\n",
    "# model.add(Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.2, activation = 'tanh'))) # weight drop on recurrent layers using recurrent_dropout\n",
    "# # model.add(GlobalMaxPooling1D())\n",
    "# # model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(63, activation=\"softmax\"))\n",
    "\n",
    "# model.summary()\n",
    "# # model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam', metrics = ['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "\n",
    "# train the model\n",
    "# model.fit(x_train, y_train, X_val=x_val, y_val=y_val,\n",
    "#     epoch_num=15, optimizer='adam', verbose=True)\n",
    "# history = model.fit(x_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=15,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "385763db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_10 (Embedding)    (None, 1000, 300)         6000000   \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 996, 128)          192128    \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 199, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 199, 128)          0         \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 199, 256)         263168    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 199, 256)          0         \n",
      "                                                                 \n",
      " Attention (SeqSelfAttention  (None, 199, 256)         16449     \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 50944)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 63)                3209535   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,681,280\n",
      "Trainable params: 3,681,280\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Model: CNN Bilstm attention Model \n",
    "def hybrid_model():\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Conv1D(filters = 128, kernel_size = 5, activation = 'relu')(embedded_sequences)  #, padding = 'same'\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    lstm_out = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    lstm_out = Dropout(0.2)(lstm_out)\n",
    "    attention_mul = SeqSelfAttention(attention_width=15, attention_activation='relu',name='Attention')(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(63, activation='softmax')(attention_mul)\n",
    "    model = Model(inputs=[sequence_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Model: Attention Model \n",
    "def attention_model():\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    attention_mul = SeqSelfAttention(attention_width=15, attention_activation='relu',name='Attention')(embedded_sequences)\n",
    "    attention_mul = Dropout(0.2)(attention_mul)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(63, activation='sigmoid')(attention_mul)\n",
    "    model = Model(inputs=[sequence_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Model: Bi-LSTM Model \n",
    "def bilstm_model():\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(embedded_sequences)\n",
    "    x1 = Dropout(0.2)(x)\n",
    "    x2 = Flatten()(x1)\n",
    "    output = Dense(63, activation='softmax')(x2)\n",
    "    model = Model(inputs=[sequence_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Model: CNN Model \n",
    "def cnn_model():\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Conv1D(filters = 128, kernel_size = 5, activation = 'relu')(embedded_sequences) \n",
    "    x1 = MaxPooling1D(5)(x)\n",
    "    x2 = Dropout(0.2)(x1)\n",
    "    x3 = Flatten()(x2)\n",
    "    output = Dense(63, activation='softmax')(x3)\n",
    "    model = Model(inputs=[sequence_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "m = hybrid_model()\n",
    "m.summary()\n",
    "\n",
    "\n",
    "m.compile(optimizer='adam', loss='mse', metrics=['acc', f1_m, precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f76691b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464/1464 [==============================] - 967s 659ms/step - loss: 0.0074 - acc: 0.6773 - f1_m: 0.6701 - precision_m: 0.7886 - recall_m: 0.5862 - val_loss: 0.0065 - val_acc: 0.7234 - val_f1_m: 0.7121 - val_precision_m: 0.8151 - val_recall_m: 0.6333\n"
     ]
    }
   ],
   "source": [
    "history = m.fit([x_train], y_train, epochs=100, batch_size=64, validation_split=0.1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3864d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLstm CNN Model \n",
    "# from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "# from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "# x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "# x = SpatialDropout1D(0.2)(x)\n",
    "# x = Bidirectional(LSTM(128, return_sequenc `1es=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "# x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "# avg_pool = GlobalAveragePooling1D()(x)\n",
    "# max_pool = GlobalMaxPooling1D()(x)\n",
    "# x = concatenate([avg_pool, max_pool]) \n",
    "# # x = Dense(128, activation='relu')(x)\n",
    "# # x = Dropout(0.1)(x)\n",
    "# preds = Dense(63, activation=\"sigmoid\")(x)\n",
    "# model = Model(sequence_input, preds)\n",
    "# model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])\n",
    "# model.summary()\n",
    "# history = model.fit(x_train, y_train, epochs = 20, validation_split=0.1, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Bilstm attention\n",
    "# from keras.layers import Input, Dense, LSTM, concatenate,Conv1D,Dropout,Bidirectional,Multiply\n",
    "# from keras.models import Model\n",
    "# from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "# from tensorflow.keras.layers import Attention\n",
    "# from keras.layers.core import *\n",
    "# from keras.models import *\n",
    "\n",
    "# lstm_units = 64\n",
    "# SINGLE_ATTENTION_VECTOR = False\n",
    "\n",
    "# def bilstm_model():\n",
    "#     sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "#     embedded_sequences = embedding_layer(sequence_input)\n",
    "#     x = Bidirectional(LSTM(128, return_sequences=True))(embedded_sequences)\n",
    "#     x1 = Dropout(0.2)(x)\n",
    "#     output = Dense(63, activation='sigmoid')(x1)\n",
    "#     model = Model(inputs=[sequence_input], outputs=output)\n",
    "#     return model\n",
    "# modelsdf = bilstm_model()\n",
    "# modelsdf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# plot metrics\n",
    "pyplot.plot(history.history[\"f1_m\"],  label=\"f1 score\")\n",
    "\n",
    "pyplot.plot(history.history[\"recall_m\"], label=\"recall\")\n",
    "pyplot.plot(history.history['acc'] , label=\"accuracy\")\n",
    "pyplot.title('Evaluation stats (Train)')\n",
    "pyplot.xlabel(\"epoch\")\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7442a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history[\"val_f1_m\"],  label=\"Val f1 score\")\n",
    "\n",
    "pyplot.plot(history.history[\"val_recall_m\"], label=\"Val recall\")\n",
    "pyplot.plot(history.history['val_acc'] , label=\"Val accuracy\")\n",
    "pyplot.xlabel(\"epoch\")\n",
    "\n",
    "pyplot.title('Evaluation stats (Test)')\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "pyplot.plot(history.history[\"loss\"],  label=\"loss (train)\")\n",
    "pyplot.xlabel(\"epoch\")\n",
    "pyplot.ylabel(\"loss\")\n",
    "\n",
    "pyplot.title('Model Loss (train)')\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "pyplot.plot(history.history[\"val_loss\"],  label=\"loss (test)\")\n",
    "pyplot.xlabel(\"epoch\")\n",
    "pyplot.ylabel(\"loss\")\n",
    "\n",
    "pyplot.title('Model Loss (test)')\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = m.to_json()\n",
    "with open(\"proposed_hybrid_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "m.save_weights(\"proposed_hybrid_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "print(\"*****Loading pre-trained GloVe model for Nepali*******\")\n",
    "# Load the pre-trained GloVe model for Nepali\n",
    "wv = KeyedVectors.load_word2vec_format('processed.glove', binary=False)\n",
    "print(\"*****Completed*******\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify News Text to Category (Step 1)\n",
    "\n",
    "politicsNews = \"नेपाली काँग्रेसका सांसद बद्रीप्रसाद पाण्डेले एमाले अध्यक्ष केपी शर्मा ओलीले सरकारमाथि नै धावा बोल्ने काम गरिरहेको आरोप लगाउनु भएको छ । शनिबार प्रतिनिधिसभा बैठकमा बोल्दै उहाँले संविधानले नचिनेको ‘उच्चस्तरीय राजनीतिक संयन्त्रको संयोजक हुँ’ भन्दै ओलीले कार्यपालिकामाथि नै धावा बोल्ने काम गरिरहेको बताउनु भएको हो । सांसद पाण्डेले प्रतिनिधिसभा विघटन गर्नु संविधान विपरित हो भन्ने अदालतको फैसलामाथि नै अपमान गर्ने काम ओलीले गरिरहेको भन्दै आक्रोश समेत व्यक्त गर्नु भयो । संविधानले प्रधानमन्त्रीभन्दा माथि कार्यपालिकामा कोही पनि नहुने व्यवस्था गरे पनि ओलीले आफूलाई माथि छु भन्ने ठानेको उहाँको भनाई थियो ।\"\n",
    "chinaNews = \"चीनमा गत जनवरी १३ देखि १९ को बीचमा लगभग १३ हजार कोभिड– १९ सङ्क्रमणको कारण मृत्यु भएको छ । गत जनवरी १२ सम्म अस्पतालमा कोभिडका कारण ६० हजार मानिसको मृत्यु भइसकेको थियो । अस्पतालमा भर्ना भएका छ सय ८१ बिरामीको कोरोना भाइरस सङ्क्रमणका कारण श्वासप्रश्वासको समस्याबाट मृत्यु भएको र एघार हजार नौ सय ७७ जनाको सङ्क्रमणसँगै अन्य रोगका कारण मृत्यु भएका चीनको सेन्टर फर डिजिज कन्ट्रोल एण्ड प्रिभेन्सन (सिडिसि) ले शनिबार जारी एक विज्ञप्तिमा जनाएको छ । गत डिसेम्बरमा चीनले शून्य–कोभिड नीति त्यागेपछि यस रोगबाट ६० हजार भन्दा बढी मानिसहरूको मृत्यु भएको सिडिसिले जनाएको छ ।\"\n",
    "sportsNews = \"इटहरी उपमहानगरपालिकास्थित जनता माविको खेलमैदानमा आज सम्पन्न प्रधानमन्त्री कप महिला राष्ट्रिय टी-२० क्रिकेट प्रतियोगिताको उपाधि सुदूरपश्चिम प्रदेशले जितेको छ । फाइनल खेलमा घरेलु टोली प्रदेश नं १ लाई छ विकेटले पराजित गर्दै सुदूरपश्चिम विजयी भएको हो । प्रदेश नं १ ले दिएको एक सय दुई रनको लक्ष्य पाएको सुदूरपश्चिमले एक बल बाँकी छँदा लक्ष्य पूरा गरेको थियो । सुदूरपश्चिमको जितका लागि अन्तिम ओभरमा आठ रन आवश्यक आवश्यक थियो । जसमा ओभरको दोस्रो बलमा कविता कुँवरले छक्का प्रहार गरी टीमलाई विजयी बनाइन् । खेलको सुरुआतमा राम्रो प्रदर्शन नसकेको सुदूरपश्चिमको खेल मध्यक्रमका ब्याटर सम्झना खड्का र डली भट्टले सम्हालेका थिए । सम्झनाले ३३ बलमा दुई चौकासहित अविजित २७ रन बनाउँदा डलीले १६ बलमा एक चौका र दुई छक्कासहित २२ रनको योगदान दिएकी थिइन् । कविता १९ रनमा अविजित भइन् । बलिङतर्फ सवनम राई, हिरनमई रोय, रुविना क्षेत्री र सङ्गीता राईले १-१ विकेट लिएका थिए । टस जितेर पहिले ब्याटिङ गरेको प्रदेश नं १ ले २० ओभरमा पाँच विकेटको क्षतिमा एक सय एक रन बनाएको थियो । प्रदेश नं १ का लागि ओपनर काजल श्रेष्ठ र कप्तान रुविनाले ३६ रनको सुरुआती साझेदारी गरेका थिए ।\"\n",
    "economicNews = \"नेपाल ट्रक यातायात व्यवसायी महासंघको एक प्रतिनिधि मण्डलले उपप्रधान तथा अर्थमन्त्री विष्णुप्रसाद पौडेलबीच शुक्रबार अर्थ मन्त्रालयमा भेटघाट सम्पन्न भएको छ । हाल यातायात क्षेत्रको ढुवानीमा देखिएको समस्याको बारेमा उक्त प्रतिनिधि मण्डलले अर्थमन्त्रीको ध्यानाकर्षण गराएको छ । भेटका क्रममा मालबाहक ढुवानी क्षेत्रमा देखिएका समस्याका बारेमा पनि अर्थ मन्त्रीलाई जानकारी गराइएको थियो। अर्थमन्त्री पौडेलले व्यवसायीको समस्या समाधानका पहल गर्ने प्रतिबद्धता व्यक्त गरेको महासंघका अध्यक्ष हिरालाल श्रेष्ठले जानकारी दिए । भेटघाट कार्यक्रममा महासंघका अध्यक्ष हिरालाल श्रेष्ठ, महासचिव राजेन्द्र विक्रम बानियाँ , कोषाध्यक्ष ओम कार्की लागतका व्यवसायीहरूको सहभागिता रहेको थियो । प्रतिनिधिमण्डलले मन्त्री पौडेललाई सफल कार्यकालका लागि शुभकामना पनि व्यक्त गरेको छ ।\"\n",
    "testNews = [politicsNews,\n",
    "           sportsNews,\n",
    "           economicNews,\n",
    "           chinaNews,\n",
    "          ]\n",
    "\n",
    "# Tokenize the input text data for prediction\n",
    "tokenizer1 = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer1.fit_on_texts(testNews)\n",
    "sequences1 = tokenizer.texts_to_sequences(testNews)\n",
    "testData = pad_sequences(sequences1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', testData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88ca9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify News Text to Category (Step 2)\n",
    "\n",
    "def print_prediction(testData, model):\n",
    "    print(\"*****EVALUATE REVIEW*******\")\n",
    "    y_pred = model.predict(testData)\n",
    "    # Find the index of the highest probability for each sample\n",
    "    predicted_categories = y_pred.argmax(axis=1)\n",
    "    for each_review, each_y_pred in zip(reviews, predicted_categories):\n",
    "        print(\"News Text:\\n{0}\\nCategory -> {1}\".format(each_review, get_key(each_y_pred, labels_index)))\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Gets CategoryName from label index\n",
    "def get_key(value, my_dict):\n",
    "    for key, val in my_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "    return None\n",
    "print_prediction(testData, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb7e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "# from keras.models import model_from_json \n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "\n",
    "json_file = open('proposed_hybrid_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json, custom_objects={'SeqSelfAttention': SeqSelfAttention})\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"proposed_hybrid_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "score = loaded_model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c05483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835dd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f9748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35c784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cb577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d52f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da66203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48088dca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
